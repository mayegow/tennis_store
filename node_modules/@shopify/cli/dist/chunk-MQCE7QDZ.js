import {
  setNextDeprecationDate
} from "./chunk-LCWH3FW5.js";
import {
  z
} from "./chunk-NLUGD7PZ.js";
import {
  ClientError,
  GraphQLClient,
  GraphQLClientError,
  RequestClientError,
  allAPIs,
  buildHeaders,
  getIdentityTokenInformation,
  getPartnersToken,
  gql,
  httpsAgent,
  resolveRequestDocument,
  retryAwareRequest,
  sanitizedHeadersOutput,
  shopifyFetch
} from "./chunk-NLZ5VWA3.js";
import {
  base64URLEncode,
  randomBytes,
  randomHex,
  sha256
} from "./chunk-PP4BSPLO.js";
import {
  cacheRetrieveOrRepopulate,
  getSession,
  removeSession,
  setSession
} from "./chunk-N766LDXO.js";
import {
  AbortError,
  BugError,
  CancelExecution,
  Environment,
  FatalError,
  findPathUp,
  firstPartyDev,
  import_ts_error,
  isCloudEnvironment,
  isSpin,
  isSpinEnvironment,
  isTTY,
  isTruthy,
  keypress,
  openURL,
  outputCompleted,
  outputContent,
  outputDebug,
  outputInfo,
  outputToken,
  outputWarn,
  readFile,
  renderConfirmationPrompt,
  runWithTimer,
  serviceEnvironment,
  spinFqdn,
  stringifyMessage,
  useDeviceAuth
} from "./chunk-YK3ZIR2O.js";
import {
  sessionConstants
} from "./chunk-F6BSBHJJ.js";
import {
  moduleDirectory
} from "./chunk-T2GATXSP.js";
import {
  __commonJS,
  __require,
  __toESM,
  init_cjs_shims
} from "./chunk-POZ5MGPT.js";

// ../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/utils.js
var require_utils = __commonJS({
  "../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/utils.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var cp = __require("child_process"), UNIT_MB = 1024 * 1024, utils = {
      /**
       * exec command with maxBuffer size
       */
      exec(cmd, callback) {
        cp.exec(cmd, {
          maxBuffer: 2 * UNIT_MB,
          windowsHide: !0
        }, callback);
      },
      /**
       * spawn command
       */
      spawn(cmd, args, options2) {
        return cp.spawn(cmd, args, options2);
      },
      /**
       * Strip top lines of text
       *
       * @param  {String} text
       * @param  {Number} num
       * @return {String}
       */
      stripLine(text, num) {
        let idx = 0;
        for (; num-- > 0; ) {
          let nIdx = text.indexOf(`
`, idx);
          nIdx >= 0 && (idx = nIdx + 1);
        }
        return idx > 0 ? text.substring(idx) : text;
      },
      /**
       * Split string and stop at max parts
       *
       * @param  {Number} line
       * @param  {Number} max
       * @return {Array}
       */
      split(line, max) {
        let cols = line.trim().split(/\s+/);
        return cols.length > max && (cols[max - 1] = cols.slice(max - 1).join(" ")), cols;
      },
      /**
       * Extract columns from table text
       *
       * Example:
       *
       * ```
       * extractColumns(text, [0, 2], 3)
       * ```
       *
       * From:
       * ```
       * foo       bar        bar2
       * valx      valy       valz
       * ```
       *
       * To:
       * ```
       * [ ['foo', 'bar2'], ['valx', 'valz'] ]
       * ```
       *
       * @param  {String} text  raw table text
       * @param  {Array} idxes  the column index list to extract
       * @param  {Number} max   max column number of table
       * @return {Array}
       */
      extractColumns(text, idxes, max) {
        let lines = text.split(/(\r\n|\n|\r)/), columns = [];
        return max || (max = Math.max.apply(null, idxes) + 1), lines.forEach((line) => {
          let cols = utils.split(line, max), column = [];
          idxes.forEach((idx) => {
            column.push(cols[idx] || "");
          }), columns.push(column);
        }), columns;
      },
      /**
       * parse table text to array
       *
       * From:
       * ```
       * Header1 : foo
       * Header2 : bar
       * Header3 : val
       *
       * Header1 : foo2
       * Header2 : bar2
       * Header3 : val2
       * ```
       *
       * To:
       * ```
       * [{ Header1: 'foo', Header2: 'bar', Header3: 'val' }, ...]
       * ```
       *
       * @param  {String} data raw table data
       * @return {Array}
       */
      parseTable(data) {
        let lines = data.split(/(\r\n\r\n|\r\n\n|\n\r\n)|\n\n/).filter((line) => line.trim().length > 0).map((e) => e.split(/(\r\n|\n|\r)/).filter((line) => line.trim().length > 0));
        return lines.forEach((line) => {
          for (let index = 0; line[index]; ) {
            let entry = line[index];
            entry.startsWith(" ") ? (line[index - 1] += entry.trimLeft(), line.splice(index, 1)) : index += 1;
          }
        }), lines.map((line) => {
          let row = {};
          return line.forEach((string) => {
            let splitterIndex = string.indexOf(":"), key = string.slice(0, splitterIndex).trim();
            row[key] = string.slice(splitterIndex + 1).trim();
          }), row;
        });
      }
    };
    module2.exports = utils;
  }
});

// ../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/find_pid.js
var require_find_pid = __commonJS({
  "../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/find_pid.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var os = __require("os"), fs = __require("fs"), utils = require_utils(), ensureDir = (path) => new Promise((resolve, reject) => {
      fs.existsSync(path) ? resolve() : fs.mkdir(path, (err2) => {
        err2 ? reject(err2) : resolve();
      });
    }), finders = {
      darwin(port) {
        return new Promise((resolve, reject) => {
          utils.exec("netstat -anv -p TCP && netstat -anv -p UDP", function(err2, stdout, stderr) {
            if (err2)
              reject(err2);
            else {
              if (err2 = stderr.toString().trim(), err2) {
                reject(err2);
                return;
              }
              let data = utils.stripLine(stdout.toString(), 2), found = utils.extractColumns(data, [0, 3, 8], 10).filter((row) => !!String(row[0]).match(/^(udp|tcp)/)).find((row) => {
                let matches = String(row[1]).match(/\.(\d+)$/);
                if (matches && matches[1] === String(port))
                  return !0;
              });
              found && found[2].length ? resolve(parseInt(found[2], 10)) : reject(new Error(`pid of port (${port}) not found`));
            }
          });
        });
      },
      freebsd: "darwin",
      sunos: "darwin",
      linux(port) {
        return new Promise((resolve, reject) => {
          let cmd = "netstat -tunlp";
          utils.exec(cmd, function(err2, stdout, stderr) {
            if (err2)
              reject(err2);
            else {
              let warn = stderr.toString().trim();
              warn && console.warn(warn);
              let data = utils.stripLine(stdout.toString(), 2), columns = utils.extractColumns(data, [3, 6], 7).find((column) => {
                let matches = String(column[0]).match(/:(\d+)$/);
                if (matches && matches[1] === String(port))
                  return !0;
              });
              if (columns && columns[1]) {
                let pid = columns[1].split("/", 1)[0];
                pid.length ? resolve(parseInt(pid, 10)) : reject(new Error(`pid of port (${port}) not found`));
              } else
                reject(new Error(`pid of port (${port}) not found`));
            }
          });
        });
      },
      win32(port) {
        return new Promise((resolve, reject) => {
          utils.exec("netstat -ano", function(err2, stdout, stderr) {
            if (err2)
              reject(err2);
            else {
              if (err2 = stderr.toString().trim(), err2) {
                reject(err2);
                return;
              }
              let data = utils.stripLine(stdout.toString(), 4), columns = utils.extractColumns(data, [1, 4], 5).find((column) => {
                let matches = String(column[0]).match(/:(\d+)$/);
                if (matches && matches[1] === String(port))
                  return !0;
              });
              columns && columns[1].length && parseInt(columns[1], 10) > 0 ? resolve(parseInt(columns[1], 10)) : reject(new Error(`pid of port (${port}) not found`));
            }
          });
        });
      },
      android(port) {
        return new Promise((resolve, reject) => {
          let dir = os.tmpdir() + "/.find-process", file = dir + "/" + process.pid, cmd = 'netstat -tunp >> "' + file + '"';
          ensureDir(dir).then(() => {
            utils.exec(cmd, () => {
              fs.readFile(file, "utf8", (err2, data) => {
                if (fs.unlink(file, () => {
                }), err2)
                  reject(err2);
                else {
                  data = utils.stripLine(data, 2);
                  let columns = utils.extractColumns(data, [3, 6], 7).find((column) => {
                    let matches = String(column[0]).match(/:(\d+)$/);
                    if (matches && matches[1] === String(port))
                      return !0;
                  });
                  if (columns && columns[1]) {
                    let pid = columns[1].split("/", 1)[0];
                    pid.length ? resolve(parseInt(pid, 10)) : reject(new Error(`pid of port (${port}) not found`));
                  } else
                    reject(new Error(`pid of port (${port}) not found`));
                }
              });
            });
          });
        });
      }
    };
    function findPidByPort(port) {
      let platform = process.platform;
      return new Promise((resolve, reject) => {
        if (!(platform in finders))
          return reject(new Error(`platform ${platform} is unsupported`));
        let findPid = finders[platform];
        typeof findPid == "string" && (findPid = finders[findPid]), findPid(port).then(resolve, reject);
      });
    }
    module2.exports = findPidByPort;
  }
});

// ../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/find_process.js
var require_find_process = __commonJS({
  "../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/find_process.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var path = __require("path"), utils = require_utils();
    function matchName(text, name) {
      return name ? text && text.match ? text.match(name) : !1 : !0;
    }
    function fetchBin(cmd) {
      let pieces = cmd.split(path.sep), last = pieces[pieces.length - 1];
      last && (pieces[pieces.length - 1] = last.split(" ")[0]);
      let fixed = [];
      for (let part of pieces) {
        let optIdx = part.indexOf(" -");
        if (optIdx >= 0) {
          fixed.push(part.substring(0, optIdx).trim());
          break;
        } else if (part.endsWith(" ")) {
          fixed.push(part.trim());
          break;
        }
        fixed.push(part);
      }
      return fixed.join(path.sep);
    }
    function fetchName(fullpath) {
      if (process.platform === "darwin") {
        let idx = fullpath.indexOf(".app/");
        if (idx >= 0)
          return path.basename(fullpath.substring(0, idx));
      }
      return path.basename(fullpath);
    }
    var finders = {
      darwin(cond) {
        return new Promise((resolve, reject) => {
          let cmd;
          "pid" in cond ? cmd = `ps -p ${cond.pid} -ww -o pid,ppid,uid,gid,args` : cmd = "ps ax -ww -o pid,ppid,uid,gid,args", utils.exec(cmd, function(err2, stdout, stderr) {
            if (err2)
              "pid" in cond ? resolve([]) : reject(err2);
            else {
              if (err2 = stderr.toString().trim(), err2) {
                reject(err2);
                return;
              }
              let data = utils.stripLine(stdout.toString(), 1), list = utils.extractColumns(data, [0, 1, 2, 3, 4], 5).filter((column) => column[0] && cond.pid ? column[0] === String(cond.pid) : column[4] && cond.name ? matchName(column[4], cond.name) : !!column[0]).map((column) => {
                let cmd2 = String(column[4]), bin = fetchBin(cmd2);
                return {
                  pid: parseInt(column[0], 10),
                  ppid: parseInt(column[1], 10),
                  uid: parseInt(column[2], 10),
                  gid: parseInt(column[3], 10),
                  name: fetchName(bin),
                  bin,
                  cmd: column[4]
                };
              });
              cond.strict && cond.name && (list = list.filter((item) => item.name === cond.name)), resolve(list);
            }
          });
        });
      },
      linux: "darwin",
      sunos: "darwin",
      freebsd: "darwin",
      win32(cond) {
        return new Promise((resolve, reject) => {
          let cmd = "Get-CimInstance -className win32_process | select Name,ProcessId,ParentProcessId,CommandLine,ExecutablePath", lines = [], proc = utils.spawn("powershell.exe", ["/c", cmd], { detached: !1, windowsHide: !0 });
          proc.stdout.on("data", (data) => {
            lines.push(data.toString());
          }), proc.on("close", (code) => {
            if (code !== 0)
              return reject(new Error("Command '" + cmd + "' terminated with code: " + code));
            let list = utils.parseTable(lines.join("")).filter((row) => {
              if ("pid" in cond)
                return row.ProcessId === String(cond.pid);
              if (cond.name) {
                let rowName = row.Name || "";
                return cond.strict ? rowName === cond.name || rowName.endsWith(".exe") && rowName.slice(0, -4) === cond.name : matchName(row.CommandLine || rowName, cond.name);
              } else
                return !0;
            }).map((row) => ({
              pid: parseInt(row.ProcessId, 10),
              ppid: parseInt(row.ParentProcessId, 10),
              // uid: void 0,
              // gid: void 0,
              bin: row.ExecutablePath,
              name: row.Name || "",
              cmd: row.CommandLine
            }));
            resolve(list);
          });
        });
      },
      android(cond) {
        return new Promise((resolve, reject) => {
          let cmd = "ps";
          utils.exec(cmd, function(err2, stdout, stderr) {
            if (err2)
              "pid" in cond ? resolve([]) : reject(err2);
            else {
              if (err2 = stderr.toString().trim(), err2) {
                reject(err2);
                return;
              }
              let data = utils.stripLine(stdout.toString(), 1), list = utils.extractColumns(data, [0, 3], 4).filter((column) => column[0] && cond.pid ? column[0] === String(cond.pid) : column[1] && cond.name ? matchName(column[1], cond.name) : !!column[0]).map((column) => {
                let cmd2 = String(column[1]), bin = fetchBin(cmd2);
                return {
                  pid: parseInt(column[0], 10),
                  // ppid: void 0,
                  // uid: void 0,
                  // gid: void 0,
                  name: fetchName(bin),
                  bin,
                  cmd: cmd2
                };
              });
              cond.strict && cond.name && (list = list.filter((item) => item.name === cond.name)), resolve(list);
            }
          });
        });
      }
    };
    function findProcess2(cond) {
      let platform = process.platform;
      return new Promise((resolve, reject) => {
        if (!(platform in finders))
          return reject(new Error(`platform ${platform} is unsupported`));
        let find = finders[platform];
        typeof find == "string" && (find = finders[find]), find(cond).then(resolve, reject);
      });
    }
    module2.exports = findProcess2;
  }
});

// ../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/find.js
var require_find = __commonJS({
  "../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/lib/find.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var findPid = require_find_pid(), findProcess2 = require_find_process(), findBy = {
      port(port, strict) {
        return findPid(port, strict).then((pid) => findBy.pid(pid, strict), () => []);
      },
      pid(pid, strict) {
        return findProcess2({
          pid,
          strict
        });
      },
      name(name, strict) {
        return findProcess2({
          name,
          strict
        });
      }
    };
    function find(by, value, strict) {
      return new Promise((resolve, reject) => {
        if (!(by in findBy))
          reject(new Error(`do not support find by "${by}"`));
        else {
          let isNumber = /^\d+$/.test(value);
          by === "pid" && !isNumber ? reject(new Error("pid must be a number")) : by === "port" && !isNumber ? reject(new Error("port must be a number")) : findBy[by](value, strict).then(resolve, reject);
        }
      });
    }
    module2.exports = find;
  }
});

// ../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/index.js
var require_find_process2 = __commonJS({
  "../../node_modules/.pnpm/find-process@1.4.7/node_modules/find-process/index.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    module2.exports = require_find();
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/parser.js
var require_parser = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/parser.js"(exports2) {
    "use strict";
    init_cjs_shims();
    exports2.load = function(received, defaults, onto = {}) {
      var k, ref, v;
      for (k in defaults)
        v = defaults[k], onto[k] = (ref = received[k]) != null ? ref : v;
      return onto;
    };
    exports2.overwrite = function(received, defaults, onto = {}) {
      var k, v;
      for (k in received)
        v = received[k], defaults[k] !== void 0 && (onto[k] = v);
      return onto;
    };
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/DLList.js
var require_DLList = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/DLList.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var DLList;
    DLList = class {
      constructor(incr, decr) {
        this.incr = incr, this.decr = decr, this._first = null, this._last = null, this.length = 0;
      }
      push(value) {
        var node;
        this.length++, typeof this.incr == "function" && this.incr(), node = {
          value,
          prev: this._last,
          next: null
        }, this._last != null ? (this._last.next = node, this._last = node) : this._first = this._last = node;
      }
      shift() {
        var value;
        if (this._first != null)
          return this.length--, typeof this.decr == "function" && this.decr(), value = this._first.value, (this._first = this._first.next) != null ? this._first.prev = null : this._last = null, value;
      }
      first() {
        if (this._first != null)
          return this._first.value;
      }
      getArray() {
        var node, ref, results;
        for (node = this._first, results = []; node != null; )
          results.push((ref = node, node = node.next, ref.value));
        return results;
      }
      forEachShift(cb) {
        var node;
        for (node = this.shift(); node != null; )
          cb(node), node = this.shift();
      }
      debug() {
        var node, ref, ref1, ref2, results;
        for (node = this._first, results = []; node != null; )
          results.push((ref = node, node = node.next, {
            value: ref.value,
            prev: (ref1 = ref.prev) != null ? ref1.value : void 0,
            next: (ref2 = ref.next) != null ? ref2.value : void 0
          }));
        return results;
      }
    };
    module2.exports = DLList;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Events.js
var require_Events = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Events.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var Events2;
    Events2 = class {
      constructor(instance) {
        if (this.instance = instance, this._events = {}, this.instance.on != null || this.instance.once != null || this.instance.removeAllListeners != null)
          throw new Error("An Emitter already exists for this object");
        this.instance.on = (name, cb) => this._addListener(name, "many", cb), this.instance.once = (name, cb) => this._addListener(name, "once", cb), this.instance.removeAllListeners = (name = null) => name != null ? delete this._events[name] : this._events = {};
      }
      _addListener(name, status, cb) {
        var base;
        return (base = this._events)[name] == null && (base[name] = []), this._events[name].push({
          cb,
          status
        }), this.instance;
      }
      listenerCount(name) {
        return this._events[name] != null ? this._events[name].length : 0;
      }
      trigger(name, ...args) {
        var _this = this;
        return _asyncToGenerator2(function* () {
          var e, promises;
          try {
            return name !== "debug" && _this.trigger("debug", `Event triggered: ${name}`, args), _this._events[name] == null ? void 0 : (_this._events[name] = _this._events[name].filter(function(listener) {
              return listener.status !== "none";
            }), promises = _this._events[name].map(
              /* @__PURE__ */ function() {
                var _ref = _asyncToGenerator2(function* (listener) {
                  var e2, returned;
                  if (listener.status !== "none") {
                    listener.status === "once" && (listener.status = "none");
                    try {
                      return returned = typeof listener.cb == "function" ? listener.cb(...args) : void 0, typeof returned?.then == "function" ? yield returned : returned;
                    } catch (error) {
                      return e2 = error, _this.trigger("error", e2), null;
                    }
                  }
                });
                return function(_x) {
                  return _ref.apply(this, arguments);
                };
              }()
            ), (yield Promise.all(promises)).find(function(x) {
              return x != null;
            }));
          } catch (error) {
            return e = error, _this.trigger("error", e), null;
          }
        })();
      }
    };
    module2.exports = Events2;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Queues.js
var require_Queues = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Queues.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var DLList, Events2, Queues;
    DLList = require_DLList();
    Events2 = require_Events();
    Queues = class {
      constructor(num_priorities) {
        var i;
        this.Events = new Events2(this), this._length = 0, this._lists = function() {
          var j, ref, results;
          for (results = [], i = j = 1, ref = num_priorities; 1 <= ref ? j <= ref : j >= ref; i = 1 <= ref ? ++j : --j)
            results.push(new DLList(() => this.incr(), () => this.decr()));
          return results;
        }.call(this);
      }
      incr() {
        if (this._length++ === 0)
          return this.Events.trigger("leftzero");
      }
      decr() {
        if (--this._length === 0)
          return this.Events.trigger("zero");
      }
      push(job) {
        return this._lists[job.options.priority].push(job);
      }
      queued(priority) {
        return priority != null ? this._lists[priority].length : this._length;
      }
      shiftAll(fn) {
        return this._lists.forEach(function(list) {
          return list.forEachShift(fn);
        });
      }
      getFirst(arr = this._lists) {
        var j, len, list;
        for (j = 0, len = arr.length; j < len; j++)
          if (list = arr[j], list.length > 0)
            return list;
        return [];
      }
      shiftLastFrom(priority) {
        return this.getFirst(this._lists.slice(priority).reverse()).shift();
      }
    };
    module2.exports = Queues;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/BottleneckError.js
var require_BottleneckError = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/BottleneckError.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var BottleneckError;
    BottleneckError = class extends Error {
    };
    module2.exports = BottleneckError;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Job.js
var require_Job = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Job.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var BottleneckError, DEFAULT_PRIORITY, Job, NUM_PRIORITIES, parser2;
    NUM_PRIORITIES = 10;
    DEFAULT_PRIORITY = 5;
    parser2 = require_parser();
    BottleneckError = require_BottleneckError();
    Job = class {
      constructor(task, args, options2, jobDefaults, rejectOnDrop, Events2, _states, Promise2) {
        this.task = task, this.args = args, this.rejectOnDrop = rejectOnDrop, this.Events = Events2, this._states = _states, this.Promise = Promise2, this.options = parser2.load(options2, jobDefaults), this.options.priority = this._sanitizePriority(this.options.priority), this.options.id === jobDefaults.id && (this.options.id = `${this.options.id}-${this._randomIndex()}`), this.promise = new this.Promise((_resolve, _reject) => {
          this._resolve = _resolve, this._reject = _reject;
        }), this.retryCount = 0;
      }
      _sanitizePriority(priority) {
        var sProperty;
        return sProperty = ~~priority !== priority ? DEFAULT_PRIORITY : priority, sProperty < 0 ? 0 : sProperty > NUM_PRIORITIES - 1 ? NUM_PRIORITIES - 1 : sProperty;
      }
      _randomIndex() {
        return Math.random().toString(36).slice(2);
      }
      doDrop({
        error,
        message = "This job has been dropped by Bottleneck"
      } = {}) {
        return this._states.remove(this.options.id) ? (this.rejectOnDrop && this._reject(error ?? new BottleneckError(message)), this.Events.trigger("dropped", {
          args: this.args,
          options: this.options,
          task: this.task,
          promise: this.promise
        }), !0) : !1;
      }
      _assertStatus(expected) {
        var status;
        if (status = this._states.jobStatus(this.options.id), !(status === expected || expected === "DONE" && status === null))
          throw new BottleneckError(`Invalid job status ${status}, expected ${expected}. Please open an issue at https://github.com/SGrondin/bottleneck/issues`);
      }
      doReceive() {
        return this._states.start(this.options.id), this.Events.trigger("received", {
          args: this.args,
          options: this.options
        });
      }
      doQueue(reachedHWM, blocked) {
        return this._assertStatus("RECEIVED"), this._states.next(this.options.id), this.Events.trigger("queued", {
          args: this.args,
          options: this.options,
          reachedHWM,
          blocked
        });
      }
      doRun() {
        return this.retryCount === 0 ? (this._assertStatus("QUEUED"), this._states.next(this.options.id)) : this._assertStatus("EXECUTING"), this.Events.trigger("scheduled", {
          args: this.args,
          options: this.options
        });
      }
      doExecute(chained, clearGlobalState, run, free) {
        var _this = this;
        return _asyncToGenerator2(function* () {
          var error, eventInfo, passed;
          _this.retryCount === 0 ? (_this._assertStatus("RUNNING"), _this._states.next(_this.options.id)) : _this._assertStatus("EXECUTING"), eventInfo = {
            args: _this.args,
            options: _this.options,
            retryCount: _this.retryCount
          }, _this.Events.trigger("executing", eventInfo);
          try {
            if (passed = yield chained != null ? chained.schedule(_this.options, _this.task, ..._this.args) : _this.task(..._this.args), clearGlobalState())
              return _this.doDone(eventInfo), yield free(_this.options, eventInfo), _this._assertStatus("DONE"), _this._resolve(passed);
          } catch (error1) {
            return error = error1, _this._onFailure(error, eventInfo, clearGlobalState, run, free);
          }
        })();
      }
      doExpire(clearGlobalState, run, free) {
        var error, eventInfo;
        return this._states.jobStatus(this.options.id === "RUNNING") && this._states.next(this.options.id), this._assertStatus("EXECUTING"), eventInfo = {
          args: this.args,
          options: this.options,
          retryCount: this.retryCount
        }, error = new BottleneckError(`This job timed out after ${this.options.expiration} ms.`), this._onFailure(error, eventInfo, clearGlobalState, run, free);
      }
      _onFailure(error, eventInfo, clearGlobalState, run, free) {
        var _this2 = this;
        return _asyncToGenerator2(function* () {
          var retry, retryAfter;
          if (clearGlobalState())
            return retry = yield _this2.Events.trigger("failed", error, eventInfo), retry != null ? (retryAfter = ~~retry, _this2.Events.trigger("retry", `Retrying ${_this2.options.id} after ${retryAfter} ms`, eventInfo), _this2.retryCount++, run(retryAfter)) : (_this2.doDone(eventInfo), yield free(_this2.options, eventInfo), _this2._assertStatus("DONE"), _this2._reject(error));
        })();
      }
      doDone(eventInfo) {
        return this._assertStatus("EXECUTING"), this._states.next(this.options.id), this.Events.trigger("done", eventInfo);
      }
    };
    module2.exports = Job;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/LocalDatastore.js
var require_LocalDatastore = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/LocalDatastore.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var BottleneckError, LocalDatastore, parser2;
    parser2 = require_parser();
    BottleneckError = require_BottleneckError();
    LocalDatastore = class {
      constructor(instance, storeOptions, storeInstanceOptions) {
        this.instance = instance, this.storeOptions = storeOptions, this.clientId = this.instance._randomIndex(), parser2.load(storeInstanceOptions, storeInstanceOptions, this), this._nextRequest = this._lastReservoirRefresh = this._lastReservoirIncrease = Date.now(), this._running = 0, this._done = 0, this._unblockTime = 0, this.ready = this.Promise.resolve(), this.clients = {}, this._startHeartbeat();
      }
      _startHeartbeat() {
        var base;
        return this.heartbeat == null && (this.storeOptions.reservoirRefreshInterval != null && this.storeOptions.reservoirRefreshAmount != null || this.storeOptions.reservoirIncreaseInterval != null && this.storeOptions.reservoirIncreaseAmount != null) ? typeof (base = this.heartbeat = setInterval(() => {
          var amount, incr, maximum, now, reservoir;
          if (now = Date.now(), this.storeOptions.reservoirRefreshInterval != null && now >= this._lastReservoirRefresh + this.storeOptions.reservoirRefreshInterval && (this._lastReservoirRefresh = now, this.storeOptions.reservoir = this.storeOptions.reservoirRefreshAmount, this.instance._drainAll(this.computeCapacity())), this.storeOptions.reservoirIncreaseInterval != null && now >= this._lastReservoirIncrease + this.storeOptions.reservoirIncreaseInterval) {
            var _this$storeOptions = this.storeOptions;
            if (amount = _this$storeOptions.reservoirIncreaseAmount, maximum = _this$storeOptions.reservoirIncreaseMaximum, reservoir = _this$storeOptions.reservoir, this._lastReservoirIncrease = now, incr = maximum != null ? Math.min(amount, maximum - reservoir) : amount, incr > 0)
              return this.storeOptions.reservoir += incr, this.instance._drainAll(this.computeCapacity());
          }
        }, this.heartbeatInterval)).unref == "function" ? base.unref() : void 0 : clearInterval(this.heartbeat);
      }
      __publish__(message) {
        var _this = this;
        return _asyncToGenerator2(function* () {
          return yield _this.yieldLoop(), _this.instance.Events.trigger("message", message.toString());
        })();
      }
      __disconnect__(flush) {
        var _this2 = this;
        return _asyncToGenerator2(function* () {
          return yield _this2.yieldLoop(), clearInterval(_this2.heartbeat), _this2.Promise.resolve();
        })();
      }
      yieldLoop(t = 0) {
        return new this.Promise(function(resolve, reject) {
          return setTimeout(resolve, t);
        });
      }
      computePenalty() {
        var ref;
        return (ref = this.storeOptions.penalty) != null ? ref : 15 * this.storeOptions.minTime || 5e3;
      }
      __updateSettings__(options2) {
        var _this3 = this;
        return _asyncToGenerator2(function* () {
          return yield _this3.yieldLoop(), parser2.overwrite(options2, options2, _this3.storeOptions), _this3._startHeartbeat(), _this3.instance._drainAll(_this3.computeCapacity()), !0;
        })();
      }
      __running__() {
        var _this4 = this;
        return _asyncToGenerator2(function* () {
          return yield _this4.yieldLoop(), _this4._running;
        })();
      }
      __queued__() {
        var _this5 = this;
        return _asyncToGenerator2(function* () {
          return yield _this5.yieldLoop(), _this5.instance.queued();
        })();
      }
      __done__() {
        var _this6 = this;
        return _asyncToGenerator2(function* () {
          return yield _this6.yieldLoop(), _this6._done;
        })();
      }
      __groupCheck__(time) {
        var _this7 = this;
        return _asyncToGenerator2(function* () {
          return yield _this7.yieldLoop(), _this7._nextRequest + _this7.timeout < time;
        })();
      }
      computeCapacity() {
        var maxConcurrent, reservoir, _this$storeOptions2 = this.storeOptions;
        return maxConcurrent = _this$storeOptions2.maxConcurrent, reservoir = _this$storeOptions2.reservoir, maxConcurrent != null && reservoir != null ? Math.min(maxConcurrent - this._running, reservoir) : maxConcurrent != null ? maxConcurrent - this._running : reservoir ?? null;
      }
      conditionsCheck(weight) {
        var capacity;
        return capacity = this.computeCapacity(), capacity == null || weight <= capacity;
      }
      __incrementReservoir__(incr) {
        var _this8 = this;
        return _asyncToGenerator2(function* () {
          var reservoir;
          return yield _this8.yieldLoop(), reservoir = _this8.storeOptions.reservoir += incr, _this8.instance._drainAll(_this8.computeCapacity()), reservoir;
        })();
      }
      __currentReservoir__() {
        var _this9 = this;
        return _asyncToGenerator2(function* () {
          return yield _this9.yieldLoop(), _this9.storeOptions.reservoir;
        })();
      }
      isBlocked(now) {
        return this._unblockTime >= now;
      }
      check(weight, now) {
        return this.conditionsCheck(weight) && this._nextRequest - now <= 0;
      }
      __check__(weight) {
        var _this10 = this;
        return _asyncToGenerator2(function* () {
          var now;
          return yield _this10.yieldLoop(), now = Date.now(), _this10.check(weight, now);
        })();
      }
      __register__(index, weight, expiration) {
        var _this11 = this;
        return _asyncToGenerator2(function* () {
          var now, wait;
          return yield _this11.yieldLoop(), now = Date.now(), _this11.conditionsCheck(weight) ? (_this11._running += weight, _this11.storeOptions.reservoir != null && (_this11.storeOptions.reservoir -= weight), wait = Math.max(_this11._nextRequest - now, 0), _this11._nextRequest = now + wait + _this11.storeOptions.minTime, {
            success: !0,
            wait,
            reservoir: _this11.storeOptions.reservoir
          }) : {
            success: !1
          };
        })();
      }
      strategyIsBlock() {
        return this.storeOptions.strategy === 3;
      }
      __submit__(queueLength, weight) {
        var _this12 = this;
        return _asyncToGenerator2(function* () {
          var blocked, now, reachedHWM;
          if (yield _this12.yieldLoop(), _this12.storeOptions.maxConcurrent != null && weight > _this12.storeOptions.maxConcurrent)
            throw new BottleneckError(`Impossible to add a job having a weight of ${weight} to a limiter having a maxConcurrent setting of ${_this12.storeOptions.maxConcurrent}`);
          return now = Date.now(), reachedHWM = _this12.storeOptions.highWater != null && queueLength === _this12.storeOptions.highWater && !_this12.check(weight, now), blocked = _this12.strategyIsBlock() && (reachedHWM || _this12.isBlocked(now)), blocked && (_this12._unblockTime = now + _this12.computePenalty(), _this12._nextRequest = _this12._unblockTime + _this12.storeOptions.minTime, _this12.instance._dropAllQueued()), {
            reachedHWM,
            blocked,
            strategy: _this12.storeOptions.strategy
          };
        })();
      }
      __free__(index, weight) {
        var _this13 = this;
        return _asyncToGenerator2(function* () {
          return yield _this13.yieldLoop(), _this13._running -= weight, _this13._done += weight, _this13.instance._drainAll(_this13.computeCapacity()), {
            running: _this13._running
          };
        })();
      }
    };
    module2.exports = LocalDatastore;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/lua.json
var require_lua = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/lua.json"(exports2, module2) {
    module2.exports = {
      "blacklist_client.lua": `local blacklist = ARGV[num_static_argv + 1]

if redis.call('zscore', client_last_seen_key, blacklist) then
  redis.call('zadd', client_last_seen_key, 0, blacklist)
end


return {}
`,
      "check.lua": `local weight = tonumber(ARGV[num_static_argv + 1])

local capacity = process_tick(now, false)['capacity']
local nextRequest = tonumber(redis.call('hget', settings_key, 'nextRequest'))

return conditions_check(capacity, weight) and nextRequest - now <= 0
`,
      "conditions_check.lua": `local conditions_check = function (capacity, weight)
  return capacity == nil or weight <= capacity
end
`,
      "current_reservoir.lua": `return process_tick(now, false)['reservoir']
`,
      "done.lua": `process_tick(now, false)

return tonumber(redis.call('hget', settings_key, 'done'))
`,
      "free.lua": `local index = ARGV[num_static_argv + 1]

redis.call('zadd', job_expirations_key, 0, index)

return process_tick(now, false)['running']
`,
      "get_time.lua": `redis.replicate_commands()

local get_time = function ()
  local time = redis.call('time')

  return tonumber(time[1]..string.sub(time[2], 1, 3))
end
`,
      "group_check.lua": `return not (redis.call('exists', settings_key) == 1)
`,
      "heartbeat.lua": `process_tick(now, true)
`,
      "increment_reservoir.lua": `local incr = tonumber(ARGV[num_static_argv + 1])

redis.call('hincrby', settings_key, 'reservoir', incr)

local reservoir = process_tick(now, true)['reservoir']

local groupTimeout = tonumber(redis.call('hget', settings_key, 'groupTimeout'))
refresh_expiration(0, 0, groupTimeout)

return reservoir
`,
      "init.lua": `local clear = tonumber(ARGV[num_static_argv + 1])
local limiter_version = ARGV[num_static_argv + 2]
local num_local_argv = num_static_argv + 2

if clear == 1 then
  redis.call('del', unpack(KEYS))
end

if redis.call('exists', settings_key) == 0 then
  -- Create
  local args = {'hmset', settings_key}

  for i = num_local_argv + 1, #ARGV do
    table.insert(args, ARGV[i])
  end

  redis.call(unpack(args))
  redis.call('hmset', settings_key,
    'nextRequest', now,
    'lastReservoirRefresh', now,
    'lastReservoirIncrease', now,
    'running', 0,
    'done', 0,
    'unblockTime', 0,
    'capacityPriorityCounter', 0
  )

else
  -- Apply migrations
  local settings = redis.call('hmget', settings_key,
    'id',
    'version'
  )
  local id = settings[1]
  local current_version = settings[2]

  if current_version ~= limiter_version then
    local version_digits = {}
    for k, v in string.gmatch(current_version, "([^.]+)") do
      table.insert(version_digits, tonumber(k))
    end

    -- 2.10.0
    if version_digits[2] < 10 then
      redis.call('hsetnx', settings_key, 'reservoirRefreshInterval', '')
      redis.call('hsetnx', settings_key, 'reservoirRefreshAmount', '')
      redis.call('hsetnx', settings_key, 'lastReservoirRefresh', '')
      redis.call('hsetnx', settings_key, 'done', 0)
      redis.call('hset', settings_key, 'version', '2.10.0')
    end

    -- 2.11.1
    if version_digits[2] < 11 or (version_digits[2] == 11 and version_digits[3] < 1) then
      if redis.call('hstrlen', settings_key, 'lastReservoirRefresh') == 0 then
        redis.call('hmset', settings_key,
          'lastReservoirRefresh', now,
          'version', '2.11.1'
        )
      end
    end

    -- 2.14.0
    if version_digits[2] < 14 then
      local old_running_key = 'b_'..id..'_running'
      local old_executing_key = 'b_'..id..'_executing'

      if redis.call('exists', old_running_key) == 1 then
        redis.call('rename', old_running_key, job_weights_key)
      end
      if redis.call('exists', old_executing_key) == 1 then
        redis.call('rename', old_executing_key, job_expirations_key)
      end
      redis.call('hset', settings_key, 'version', '2.14.0')
    end

    -- 2.15.2
    if version_digits[2] < 15 or (version_digits[2] == 15 and version_digits[3] < 2) then
      redis.call('hsetnx', settings_key, 'capacityPriorityCounter', 0)
      redis.call('hset', settings_key, 'version', '2.15.2')
    end

    -- 2.17.0
    if version_digits[2] < 17 then
      redis.call('hsetnx', settings_key, 'clientTimeout', 10000)
      redis.call('hset', settings_key, 'version', '2.17.0')
    end

    -- 2.18.0
    if version_digits[2] < 18 then
      redis.call('hsetnx', settings_key, 'reservoirIncreaseInterval', '')
      redis.call('hsetnx', settings_key, 'reservoirIncreaseAmount', '')
      redis.call('hsetnx', settings_key, 'reservoirIncreaseMaximum', '')
      redis.call('hsetnx', settings_key, 'lastReservoirIncrease', now)
      redis.call('hset', settings_key, 'version', '2.18.0')
    end

  end

  process_tick(now, false)
end

local groupTimeout = tonumber(redis.call('hget', settings_key, 'groupTimeout'))
refresh_expiration(0, 0, groupTimeout)

return {}
`,
      "process_tick.lua": `local process_tick = function (now, always_publish)

  local compute_capacity = function (maxConcurrent, running, reservoir)
    if maxConcurrent ~= nil and reservoir ~= nil then
      return math.min((maxConcurrent - running), reservoir)
    elseif maxConcurrent ~= nil then
      return maxConcurrent - running
    elseif reservoir ~= nil then
      return reservoir
    else
      return nil
    end
  end

  local settings = redis.call('hmget', settings_key,
    'id',
    'maxConcurrent',
    'running',
    'reservoir',
    'reservoirRefreshInterval',
    'reservoirRefreshAmount',
    'lastReservoirRefresh',
    'reservoirIncreaseInterval',
    'reservoirIncreaseAmount',
    'reservoirIncreaseMaximum',
    'lastReservoirIncrease',
    'capacityPriorityCounter',
    'clientTimeout'
  )
  local id = settings[1]
  local maxConcurrent = tonumber(settings[2])
  local running = tonumber(settings[3])
  local reservoir = tonumber(settings[4])
  local reservoirRefreshInterval = tonumber(settings[5])
  local reservoirRefreshAmount = tonumber(settings[6])
  local lastReservoirRefresh = tonumber(settings[7])
  local reservoirIncreaseInterval = tonumber(settings[8])
  local reservoirIncreaseAmount = tonumber(settings[9])
  local reservoirIncreaseMaximum = tonumber(settings[10])
  local lastReservoirIncrease = tonumber(settings[11])
  local capacityPriorityCounter = tonumber(settings[12])
  local clientTimeout = tonumber(settings[13])

  local initial_capacity = compute_capacity(maxConcurrent, running, reservoir)

  --
  -- Process 'running' changes
  --
  local expired = redis.call('zrangebyscore', job_expirations_key, '-inf', '('..now)

  if #expired > 0 then
    redis.call('zremrangebyscore', job_expirations_key, '-inf', '('..now)

    local flush_batch = function (batch, acc)
      local weights = redis.call('hmget', job_weights_key, unpack(batch))
                      redis.call('hdel',  job_weights_key, unpack(batch))
      local clients = redis.call('hmget', job_clients_key, unpack(batch))
                      redis.call('hdel',  job_clients_key, unpack(batch))

      -- Calculate sum of removed weights
      for i = 1, #weights do
        acc['total'] = acc['total'] + (tonumber(weights[i]) or 0)
      end

      -- Calculate sum of removed weights by client
      local client_weights = {}
      for i = 1, #clients do
        local removed = tonumber(weights[i]) or 0
        if removed > 0 then
          acc['client_weights'][clients[i]] = (acc['client_weights'][clients[i]] or 0) + removed
        end
      end
    end

    local acc = {
      ['total'] = 0,
      ['client_weights'] = {}
    }
    local batch_size = 1000

    -- Compute changes to Zsets and apply changes to Hashes
    for i = 1, #expired, batch_size do
      local batch = {}
      for j = i, math.min(i + batch_size - 1, #expired) do
        table.insert(batch, expired[j])
      end

      flush_batch(batch, acc)
    end

    -- Apply changes to Zsets
    if acc['total'] > 0 then
      redis.call('hincrby', settings_key, 'done', acc['total'])
      running = tonumber(redis.call('hincrby', settings_key, 'running', -acc['total']))
    end

    for client, weight in pairs(acc['client_weights']) do
      redis.call('zincrby', client_running_key, -weight, client)
    end
  end

  --
  -- Process 'reservoir' changes
  --
  local reservoirRefreshActive = reservoirRefreshInterval ~= nil and reservoirRefreshAmount ~= nil
  if reservoirRefreshActive and now >= lastReservoirRefresh + reservoirRefreshInterval then
    reservoir = reservoirRefreshAmount
    redis.call('hmset', settings_key,
      'reservoir', reservoir,
      'lastReservoirRefresh', now
    )
  end

  local reservoirIncreaseActive = reservoirIncreaseInterval ~= nil and reservoirIncreaseAmount ~= nil
  if reservoirIncreaseActive and now >= lastReservoirIncrease + reservoirIncreaseInterval then
    local num_intervals = math.floor((now - lastReservoirIncrease) / reservoirIncreaseInterval)
    local incr = reservoirIncreaseAmount * num_intervals
    if reservoirIncreaseMaximum ~= nil then
      incr = math.min(incr, reservoirIncreaseMaximum - (reservoir or 0))
    end
    if incr > 0 then
      reservoir = (reservoir or 0) + incr
    end
    redis.call('hmset', settings_key,
      'reservoir', reservoir,
      'lastReservoirIncrease', lastReservoirIncrease + (num_intervals * reservoirIncreaseInterval)
    )
  end

  --
  -- Clear unresponsive clients
  --
  local unresponsive = redis.call('zrangebyscore', client_last_seen_key, '-inf', (now - clientTimeout))
  local unresponsive_lookup = {}
  local terminated_clients = {}
  for i = 1, #unresponsive do
    unresponsive_lookup[unresponsive[i]] = true
    if tonumber(redis.call('zscore', client_running_key, unresponsive[i])) == 0 then
      table.insert(terminated_clients, unresponsive[i])
    end
  end
  if #terminated_clients > 0 then
    redis.call('zrem', client_running_key,         unpack(terminated_clients))
    redis.call('hdel', client_num_queued_key,      unpack(terminated_clients))
    redis.call('zrem', client_last_registered_key, unpack(terminated_clients))
    redis.call('zrem', client_last_seen_key,       unpack(terminated_clients))
  end

  --
  -- Broadcast capacity changes
  --
  local final_capacity = compute_capacity(maxConcurrent, running, reservoir)

  if always_publish or (initial_capacity ~= nil and final_capacity == nil) then
    -- always_publish or was not unlimited, now unlimited
    redis.call('publish', 'b_'..id, 'capacity:'..(final_capacity or ''))

  elseif initial_capacity ~= nil and final_capacity ~= nil and final_capacity > initial_capacity then
    -- capacity was increased
    -- send the capacity message to the limiter having the lowest number of running jobs
    -- the tiebreaker is the limiter having not registered a job in the longest time

    local lowest_concurrency_value = nil
    local lowest_concurrency_clients = {}
    local lowest_concurrency_last_registered = {}
    local client_concurrencies = redis.call('zrange', client_running_key, 0, -1, 'withscores')

    for i = 1, #client_concurrencies, 2 do
      local client = client_concurrencies[i]
      local concurrency = tonumber(client_concurrencies[i+1])

      if (
        lowest_concurrency_value == nil or lowest_concurrency_value == concurrency
      ) and (
        not unresponsive_lookup[client]
      ) and (
        tonumber(redis.call('hget', client_num_queued_key, client)) > 0
      ) then
        lowest_concurrency_value = concurrency
        table.insert(lowest_concurrency_clients, client)
        local last_registered = tonumber(redis.call('zscore', client_last_registered_key, client))
        table.insert(lowest_concurrency_last_registered, last_registered)
      end
    end

    if #lowest_concurrency_clients > 0 then
      local position = 1
      local earliest = lowest_concurrency_last_registered[1]

      for i,v in ipairs(lowest_concurrency_last_registered) do
        if v < earliest then
          position = i
          earliest = v
        end
      end

      local next_client = lowest_concurrency_clients[position]
      redis.call('publish', 'b_'..id,
        'capacity-priority:'..(final_capacity or '')..
        ':'..next_client..
        ':'..capacityPriorityCounter
      )
      redis.call('hincrby', settings_key, 'capacityPriorityCounter', '1')
    else
      redis.call('publish', 'b_'..id, 'capacity:'..(final_capacity or ''))
    end
  end

  return {
    ['capacity'] = final_capacity,
    ['running'] = running,
    ['reservoir'] = reservoir
  }
end
`,
      "queued.lua": `local clientTimeout = tonumber(redis.call('hget', settings_key, 'clientTimeout'))
local valid_clients = redis.call('zrangebyscore', client_last_seen_key, (now - clientTimeout), 'inf')
local client_queued = redis.call('hmget', client_num_queued_key, unpack(valid_clients))

local sum = 0
for i = 1, #client_queued do
  sum = sum + tonumber(client_queued[i])
end

return sum
`,
      "refresh_expiration.lua": `local refresh_expiration = function (now, nextRequest, groupTimeout)

  if groupTimeout ~= nil then
    local ttl = (nextRequest + groupTimeout) - now

    for i = 1, #KEYS do
      redis.call('pexpire', KEYS[i], ttl)
    end
  end

end
`,
      "refs.lua": `local settings_key = KEYS[1]
local job_weights_key = KEYS[2]
local job_expirations_key = KEYS[3]
local job_clients_key = KEYS[4]
local client_running_key = KEYS[5]
local client_num_queued_key = KEYS[6]
local client_last_registered_key = KEYS[7]
local client_last_seen_key = KEYS[8]

local now = tonumber(ARGV[1])
local client = ARGV[2]

local num_static_argv = 2
`,
      "register.lua": `local index = ARGV[num_static_argv + 1]
local weight = tonumber(ARGV[num_static_argv + 2])
local expiration = tonumber(ARGV[num_static_argv + 3])

local state = process_tick(now, false)
local capacity = state['capacity']
local reservoir = state['reservoir']

local settings = redis.call('hmget', settings_key,
  'nextRequest',
  'minTime',
  'groupTimeout'
)
local nextRequest = tonumber(settings[1])
local minTime = tonumber(settings[2])
local groupTimeout = tonumber(settings[3])

if conditions_check(capacity, weight) then

  redis.call('hincrby', settings_key, 'running', weight)
  redis.call('hset', job_weights_key, index, weight)
  if expiration ~= nil then
    redis.call('zadd', job_expirations_key, now + expiration, index)
  end
  redis.call('hset', job_clients_key, index, client)
  redis.call('zincrby', client_running_key, weight, client)
  redis.call('hincrby', client_num_queued_key, client, -1)
  redis.call('zadd', client_last_registered_key, now, client)

  local wait = math.max(nextRequest - now, 0)
  local newNextRequest = now + wait + minTime

  if reservoir == nil then
    redis.call('hset', settings_key,
      'nextRequest', newNextRequest
    )
  else
    reservoir = reservoir - weight
    redis.call('hmset', settings_key,
      'reservoir', reservoir,
      'nextRequest', newNextRequest
    )
  end

  refresh_expiration(now, newNextRequest, groupTimeout)

  return {true, wait, reservoir}

else
  return {false}
end
`,
      "register_client.lua": `local queued = tonumber(ARGV[num_static_argv + 1])

-- Could have been re-registered concurrently
if not redis.call('zscore', client_last_seen_key, client) then
  redis.call('zadd', client_running_key, 0, client)
  redis.call('hset', client_num_queued_key, client, queued)
  redis.call('zadd', client_last_registered_key, 0, client)
end

redis.call('zadd', client_last_seen_key, now, client)

return {}
`,
      "running.lua": `return process_tick(now, false)['running']
`,
      "submit.lua": `local queueLength = tonumber(ARGV[num_static_argv + 1])
local weight = tonumber(ARGV[num_static_argv + 2])

local capacity = process_tick(now, false)['capacity']

local settings = redis.call('hmget', settings_key,
  'id',
  'maxConcurrent',
  'highWater',
  'nextRequest',
  'strategy',
  'unblockTime',
  'penalty',
  'minTime',
  'groupTimeout'
)
local id = settings[1]
local maxConcurrent = tonumber(settings[2])
local highWater = tonumber(settings[3])
local nextRequest = tonumber(settings[4])
local strategy = tonumber(settings[5])
local unblockTime = tonumber(settings[6])
local penalty = tonumber(settings[7])
local minTime = tonumber(settings[8])
local groupTimeout = tonumber(settings[9])

if maxConcurrent ~= nil and weight > maxConcurrent then
  return redis.error_reply('OVERWEIGHT:'..weight..':'..maxConcurrent)
end

local reachedHWM = (highWater ~= nil and queueLength == highWater
  and not (
    conditions_check(capacity, weight)
    and nextRequest - now <= 0
  )
)

local blocked = strategy == 3 and (reachedHWM or unblockTime >= now)

if blocked then
  local computedPenalty = penalty
  if computedPenalty == nil then
    if minTime == 0 then
      computedPenalty = 5000
    else
      computedPenalty = 15 * minTime
    end
  end

  local newNextRequest = now + computedPenalty + minTime

  redis.call('hmset', settings_key,
    'unblockTime', now + computedPenalty,
    'nextRequest', newNextRequest
  )

  local clients_queued_reset = redis.call('hkeys', client_num_queued_key)
  local queued_reset = {}
  for i = 1, #clients_queued_reset do
    table.insert(queued_reset, clients_queued_reset[i])
    table.insert(queued_reset, 0)
  end
  redis.call('hmset', client_num_queued_key, unpack(queued_reset))

  redis.call('publish', 'b_'..id, 'blocked:')

  refresh_expiration(now, newNextRequest, groupTimeout)
end

if not blocked and not reachedHWM then
  redis.call('hincrby', client_num_queued_key, client, 1)
end

return {reachedHWM, blocked, strategy}
`,
      "update_settings.lua": `local args = {'hmset', settings_key}

for i = num_static_argv + 1, #ARGV do
  table.insert(args, ARGV[i])
end

redis.call(unpack(args))

process_tick(now, true)

local groupTimeout = tonumber(redis.call('hget', settings_key, 'groupTimeout'))
refresh_expiration(0, 0, groupTimeout)

return {}
`,
      "validate_client.lua": `if not redis.call('zscore', client_last_seen_key, client) then
  return redis.error_reply('UNKNOWN_CLIENT')
end

redis.call('zadd', client_last_seen_key, now, client)
`,
      "validate_keys.lua": `if not (redis.call('exists', settings_key) == 1) then
  return redis.error_reply('SETTINGS_KEY_NOT_FOUND')
end
`
    };
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Scripts.js
var require_Scripts = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Scripts.js"(exports2) {
    "use strict";
    init_cjs_shims();
    var headers, lua, templates;
    lua = require_lua();
    headers = {
      refs: lua["refs.lua"],
      validate_keys: lua["validate_keys.lua"],
      validate_client: lua["validate_client.lua"],
      refresh_expiration: lua["refresh_expiration.lua"],
      process_tick: lua["process_tick.lua"],
      conditions_check: lua["conditions_check.lua"],
      get_time: lua["get_time.lua"]
    };
    exports2.allKeys = function(id) {
      return [
        /*
        HASH
        */
        `b_${id}_settings`,
        /*
        HASH
        job index -> weight
        */
        `b_${id}_job_weights`,
        /*
        ZSET
        job index -> expiration
        */
        `b_${id}_job_expirations`,
        /*
        HASH
        job index -> client
        */
        `b_${id}_job_clients`,
        /*
        ZSET
        client -> sum running
        */
        `b_${id}_client_running`,
        /*
        HASH
        client -> num queued
        */
        `b_${id}_client_num_queued`,
        /*
        ZSET
        client -> last job registered
        */
        `b_${id}_client_last_registered`,
        /*
        ZSET
        client -> last seen
        */
        `b_${id}_client_last_seen`
      ];
    };
    templates = {
      init: {
        keys: exports2.allKeys,
        headers: ["process_tick"],
        refresh_expiration: !0,
        code: lua["init.lua"]
      },
      group_check: {
        keys: exports2.allKeys,
        headers: [],
        refresh_expiration: !1,
        code: lua["group_check.lua"]
      },
      register_client: {
        keys: exports2.allKeys,
        headers: ["validate_keys"],
        refresh_expiration: !1,
        code: lua["register_client.lua"]
      },
      blacklist_client: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client"],
        refresh_expiration: !1,
        code: lua["blacklist_client.lua"]
      },
      heartbeat: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !1,
        code: lua["heartbeat.lua"]
      },
      update_settings: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !0,
        code: lua["update_settings.lua"]
      },
      running: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !1,
        code: lua["running.lua"]
      },
      queued: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client"],
        refresh_expiration: !1,
        code: lua["queued.lua"]
      },
      done: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !1,
        code: lua["done.lua"]
      },
      check: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick", "conditions_check"],
        refresh_expiration: !1,
        code: lua["check.lua"]
      },
      submit: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick", "conditions_check"],
        refresh_expiration: !0,
        code: lua["submit.lua"]
      },
      register: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick", "conditions_check"],
        refresh_expiration: !0,
        code: lua["register.lua"]
      },
      free: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !0,
        code: lua["free.lua"]
      },
      current_reservoir: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !1,
        code: lua["current_reservoir.lua"]
      },
      increment_reservoir: {
        keys: exports2.allKeys,
        headers: ["validate_keys", "validate_client", "process_tick"],
        refresh_expiration: !0,
        code: lua["increment_reservoir.lua"]
      }
    };
    exports2.names = Object.keys(templates);
    exports2.keys = function(name, id) {
      return templates[name].keys(id);
    };
    exports2.payload = function(name) {
      var template;
      return template = templates[name], Array.prototype.concat(headers.refs, template.headers.map(function(h) {
        return headers[h];
      }), template.refresh_expiration ? headers.refresh_expiration : "", template.code).join(`
`);
    };
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/RedisConnection.js
var require_RedisConnection = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/RedisConnection.js"(exports, module) {
    "use strict";
    init_cjs_shims();
    function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var Events, RedisConnection, Scripts, parser;
    parser = require_parser();
    Events = require_Events();
    Scripts = require_Scripts();
    RedisConnection = function() {
      class RedisConnection {
        constructor(options = {}) {
          parser.load(options, this.defaults, this), this.Redis == null && (this.Redis = eval("require")("redis")), this.Events == null && (this.Events = new Events(this)), this.terminated = !1, this.client == null && (this.client = this.Redis.createClient(this.clientOptions)), this.subscriber = this.client.duplicate(), this.limiters = {}, this.shas = {}, this.ready = this.Promise.all([this._setup(this.client, !1), this._setup(this.subscriber, !0)]).then(() => this._loadScripts()).then(() => ({
            client: this.client,
            subscriber: this.subscriber
          }));
        }
        _setup(client, sub) {
          return client.setMaxListeners(0), new this.Promise((resolve, reject) => (client.on("error", (e) => this.Events.trigger("error", e)), sub && client.on("message", (channel, message) => {
            var ref;
            return (ref = this.limiters[channel]) != null ? ref._store.onMessage(channel, message) : void 0;
          }), client.ready ? resolve() : client.once("ready", resolve)));
        }
        _loadScript(name) {
          return new this.Promise((resolve, reject) => {
            var payload;
            return payload = Scripts.payload(name), this.client.multi([["script", "load", payload]]).exec((err2, replies) => err2 != null ? reject(err2) : (this.shas[name] = replies[0], resolve(replies[0])));
          });
        }
        _loadScripts() {
          return this.Promise.all(Scripts.names.map((k) => this._loadScript(k)));
        }
        __runCommand__(cmd) {
          var _this = this;
          return _asyncToGenerator(function* () {
            return yield _this.ready, new _this.Promise((resolve, reject) => _this.client.multi([cmd]).exec_atomic(function(err2, replies) {
              return err2 != null ? reject(err2) : resolve(replies[0]);
            }));
          })();
        }
        __addLimiter__(instance) {
          return this.Promise.all([instance.channel(), instance.channel_client()].map((channel) => new this.Promise((resolve, reject) => {
            var handler;
            return handler = (chan) => {
              if (chan === channel)
                return this.subscriber.removeListener("subscribe", handler), this.limiters[channel] = instance, resolve();
            }, this.subscriber.on("subscribe", handler), this.subscriber.subscribe(channel);
          })));
        }
        __removeLimiter__(instance) {
          var _this2 = this;
          return this.Promise.all([instance.channel(), instance.channel_client()].map(
            /* @__PURE__ */ function() {
              var _ref = _asyncToGenerator(function* (channel) {
                return _this2.terminated || (yield new _this2.Promise((resolve, reject) => _this2.subscriber.unsubscribe(channel, function(err2, chan) {
                  if (err2 != null)
                    return reject(err2);
                  if (chan === channel)
                    return resolve();
                }))), delete _this2.limiters[channel];
              });
              return function(_x) {
                return _ref.apply(this, arguments);
              };
            }()
          ));
        }
        __scriptArgs__(name, id, args, cb) {
          var keys;
          return keys = Scripts.keys(name, id), [this.shas[name], keys.length].concat(keys, args, cb);
        }
        __scriptFn__(name) {
          return this.client.evalsha.bind(this.client);
        }
        disconnect(flush = !0) {
          var i, k, len, ref;
          for (ref = Object.keys(this.limiters), i = 0, len = ref.length; i < len; i++)
            k = ref[i], clearInterval(this.limiters[k]._store.heartbeat);
          return this.limiters = {}, this.terminated = !0, this.client.end(flush), this.subscriber.end(flush), this.Promise.resolve();
        }
      }
      return RedisConnection.prototype.datastore = "redis", RedisConnection.prototype.defaults = {
        Redis: null,
        clientOptions: {},
        client: null,
        Promise,
        Events: null
      }, RedisConnection;
    }.call(void 0);
    module.exports = RedisConnection;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/IORedisConnection.js
var require_IORedisConnection = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/IORedisConnection.js"(exports, module) {
    "use strict";
    init_cjs_shims();
    function _slicedToArray(arr, i) {
      return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _nonIterableRest();
    }
    function _nonIterableRest() {
      throw new TypeError("Invalid attempt to destructure non-iterable instance");
    }
    function _iterableToArrayLimit(arr, i) {
      var _arr = [], _n = !0, _d = !1, _e = void 0;
      try {
        for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done) && (_arr.push(_s.value), !(i && _arr.length === i)); _n = !0)
          ;
      } catch (err2) {
        _d = !0, _e = err2;
      } finally {
        try {
          !_n && _i.return != null && _i.return();
        } finally {
          if (_d)
            throw _e;
        }
      }
      return _arr;
    }
    function _arrayWithHoles(arr) {
      if (Array.isArray(arr))
        return arr;
    }
    function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var Events, IORedisConnection, Scripts, parser;
    parser = require_parser();
    Events = require_Events();
    Scripts = require_Scripts();
    IORedisConnection = function() {
      class IORedisConnection {
        constructor(options = {}) {
          parser.load(options, this.defaults, this), this.Redis == null && (this.Redis = eval("require")("ioredis")), this.Events == null && (this.Events = new Events(this)), this.terminated = !1, this.clusterNodes != null ? (this.client = new this.Redis.Cluster(this.clusterNodes, this.clientOptions), this.subscriber = new this.Redis.Cluster(this.clusterNodes, this.clientOptions)) : this.client != null && this.client.duplicate == null ? this.subscriber = new this.Redis.Cluster(this.client.startupNodes, this.client.options) : (this.client == null && (this.client = new this.Redis(this.clientOptions)), this.subscriber = this.client.duplicate()), this.limiters = {}, this.ready = this.Promise.all([this._setup(this.client, !1), this._setup(this.subscriber, !0)]).then(() => (this._loadScripts(), {
            client: this.client,
            subscriber: this.subscriber
          }));
        }
        _setup(client, sub) {
          return client.setMaxListeners(0), new this.Promise((resolve, reject) => (client.on("error", (e) => this.Events.trigger("error", e)), sub && client.on("message", (channel, message) => {
            var ref;
            return (ref = this.limiters[channel]) != null ? ref._store.onMessage(channel, message) : void 0;
          }), client.status === "ready" ? resolve() : client.once("ready", resolve)));
        }
        _loadScripts() {
          return Scripts.names.forEach((name) => this.client.defineCommand(name, {
            lua: Scripts.payload(name)
          }));
        }
        __runCommand__(cmd) {
          var _this = this;
          return _asyncToGenerator(function* () {
            var _, deleted;
            yield _this.ready;
            var _ref = yield _this.client.pipeline([cmd]).exec(), _ref2 = _slicedToArray(_ref, 1), _ref2$ = _slicedToArray(_ref2[0], 2);
            return _ = _ref2$[0], deleted = _ref2$[1], deleted;
          })();
        }
        __addLimiter__(instance) {
          return this.Promise.all([instance.channel(), instance.channel_client()].map((channel) => new this.Promise((resolve, reject) => this.subscriber.subscribe(channel, () => (this.limiters[channel] = instance, resolve())))));
        }
        __removeLimiter__(instance) {
          var _this2 = this;
          return [instance.channel(), instance.channel_client()].forEach(
            /* @__PURE__ */ function() {
              var _ref3 = _asyncToGenerator(function* (channel) {
                return _this2.terminated || (yield _this2.subscriber.unsubscribe(channel)), delete _this2.limiters[channel];
              });
              return function(_x) {
                return _ref3.apply(this, arguments);
              };
            }()
          );
        }
        __scriptArgs__(name, id, args, cb) {
          var keys;
          return keys = Scripts.keys(name, id), [keys.length].concat(keys, args, cb);
        }
        __scriptFn__(name) {
          return this.client[name].bind(this.client);
        }
        disconnect(flush = !0) {
          var i, k, len, ref;
          for (ref = Object.keys(this.limiters), i = 0, len = ref.length; i < len; i++)
            k = ref[i], clearInterval(this.limiters[k]._store.heartbeat);
          return this.limiters = {}, this.terminated = !0, flush ? this.Promise.all([this.client.quit(), this.subscriber.quit()]) : (this.client.disconnect(), this.subscriber.disconnect(), this.Promise.resolve());
        }
      }
      return IORedisConnection.prototype.datastore = "ioredis", IORedisConnection.prototype.defaults = {
        Redis: null,
        clientOptions: {},
        clusterNodes: null,
        client: null,
        Promise,
        Events: null
      }, IORedisConnection;
    }.call(void 0);
    module.exports = IORedisConnection;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/RedisDatastore.js
var require_RedisDatastore = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/RedisDatastore.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function _slicedToArray2(arr, i) {
      return _arrayWithHoles2(arr) || _iterableToArrayLimit2(arr, i) || _nonIterableRest2();
    }
    function _nonIterableRest2() {
      throw new TypeError("Invalid attempt to destructure non-iterable instance");
    }
    function _iterableToArrayLimit2(arr, i) {
      var _arr = [], _n = !0, _d = !1, _e = void 0;
      try {
        for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done) && (_arr.push(_s.value), !(i && _arr.length === i)); _n = !0)
          ;
      } catch (err2) {
        _d = !0, _e = err2;
      } finally {
        try {
          !_n && _i.return != null && _i.return();
        } finally {
          if (_d)
            throw _e;
        }
      }
      return _arr;
    }
    function _arrayWithHoles2(arr) {
      if (Array.isArray(arr))
        return arr;
    }
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var BottleneckError, IORedisConnection2, RedisConnection2, RedisDatastore, parser2;
    parser2 = require_parser();
    BottleneckError = require_BottleneckError();
    RedisConnection2 = require_RedisConnection();
    IORedisConnection2 = require_IORedisConnection();
    RedisDatastore = class {
      constructor(instance, storeOptions, storeInstanceOptions) {
        this.instance = instance, this.storeOptions = storeOptions, this.originalId = this.instance.id, this.clientId = this.instance._randomIndex(), parser2.load(storeInstanceOptions, storeInstanceOptions, this), this.clients = {}, this.capacityPriorityCounters = {}, this.sharedConnection = this.connection != null, this.connection == null && (this.connection = this.instance.datastore === "redis" ? new RedisConnection2({
          Redis: this.Redis,
          clientOptions: this.clientOptions,
          Promise: this.Promise,
          Events: this.instance.Events
        }) : this.instance.datastore === "ioredis" ? new IORedisConnection2({
          Redis: this.Redis,
          clientOptions: this.clientOptions,
          clusterNodes: this.clusterNodes,
          Promise: this.Promise,
          Events: this.instance.Events
        }) : void 0), this.instance.connection = this.connection, this.instance.datastore = this.connection.datastore, this.ready = this.connection.ready.then((clients) => (this.clients = clients, this.runScript("init", this.prepareInitSettings(this.clearDatastore)))).then(() => this.connection.__addLimiter__(this.instance)).then(() => this.runScript("register_client", [this.instance.queued()])).then(() => {
          var base;
          return typeof (base = this.heartbeat = setInterval(() => this.runScript("heartbeat", []).catch((e) => this.instance.Events.trigger("error", e)), this.heartbeatInterval)).unref == "function" && base.unref(), this.clients;
        });
      }
      __publish__(message) {
        var _this = this;
        return _asyncToGenerator2(function* () {
          var client, _ref = yield _this.ready;
          return client = _ref.client, client.publish(_this.instance.channel(), `message:${message.toString()}`);
        })();
      }
      onMessage(channel, message) {
        var _this2 = this;
        return _asyncToGenerator2(function* () {
          var capacity, counter, data, drained, e, newCapacity, pos, priorityClient, rawCapacity, type;
          try {
            pos = message.indexOf(":");
            var _ref2 = [message.slice(0, pos), message.slice(pos + 1)];
            if (type = _ref2[0], data = _ref2[1], type === "capacity")
              return yield _this2.instance._drainAll(data.length > 0 ? ~~data : void 0);
            if (type === "capacity-priority") {
              var _data$split = data.split(":"), _data$split2 = _slicedToArray2(_data$split, 3);
              return rawCapacity = _data$split2[0], priorityClient = _data$split2[1], counter = _data$split2[2], capacity = rawCapacity.length > 0 ? ~~rawCapacity : void 0, priorityClient === _this2.clientId ? (drained = yield _this2.instance._drainAll(capacity), newCapacity = capacity != null ? capacity - (drained || 0) : "", yield _this2.clients.client.publish(_this2.instance.channel(), `capacity-priority:${newCapacity}::${counter}`)) : priorityClient === "" ? (clearTimeout(_this2.capacityPriorityCounters[counter]), delete _this2.capacityPriorityCounters[counter], _this2.instance._drainAll(capacity)) : _this2.capacityPriorityCounters[counter] = setTimeout(
                /* @__PURE__ */ _asyncToGenerator2(function* () {
                  var e2;
                  try {
                    return delete _this2.capacityPriorityCounters[counter], yield _this2.runScript("blacklist_client", [priorityClient]), yield _this2.instance._drainAll(capacity);
                  } catch (error) {
                    return e2 = error, _this2.instance.Events.trigger("error", e2);
                  }
                }),
                1e3
              );
            } else {
              if (type === "message")
                return _this2.instance.Events.trigger("message", data);
              if (type === "blocked")
                return yield _this2.instance._dropAllQueued();
            }
          } catch (error) {
            return e = error, _this2.instance.Events.trigger("error", e);
          }
        })();
      }
      __disconnect__(flush) {
        return clearInterval(this.heartbeat), this.sharedConnection ? this.connection.__removeLimiter__(this.instance) : this.connection.disconnect(flush);
      }
      runScript(name, args) {
        var _this3 = this;
        return _asyncToGenerator2(function* () {
          return name === "init" || name === "register_client" || (yield _this3.ready), new _this3.Promise((resolve, reject) => {
            var all_args, arr;
            return all_args = [Date.now(), _this3.clientId].concat(args), _this3.instance.Events.trigger("debug", `Calling Redis script: ${name}.lua`, all_args), arr = _this3.connection.__scriptArgs__(name, _this3.originalId, all_args, function(err2, replies) {
              return err2 != null ? reject(err2) : resolve(replies);
            }), _this3.connection.__scriptFn__(name)(...arr);
          }).catch((e) => e.message === "SETTINGS_KEY_NOT_FOUND" ? name === "heartbeat" ? _this3.Promise.resolve() : _this3.runScript("init", _this3.prepareInitSettings(!1)).then(() => _this3.runScript(name, args)) : e.message === "UNKNOWN_CLIENT" ? _this3.runScript("register_client", [_this3.instance.queued()]).then(() => _this3.runScript(name, args)) : _this3.Promise.reject(e));
        })();
      }
      prepareArray(arr) {
        var i, len, results, x;
        for (results = [], i = 0, len = arr.length; i < len; i++)
          x = arr[i], results.push(x != null ? x.toString() : "");
        return results;
      }
      prepareObject(obj) {
        var arr, k, v;
        arr = [];
        for (k in obj)
          v = obj[k], arr.push(k, v != null ? v.toString() : "");
        return arr;
      }
      prepareInitSettings(clear) {
        var args;
        return args = this.prepareObject(Object.assign({}, this.storeOptions, {
          id: this.originalId,
          version: this.instance.version,
          groupTimeout: this.timeout,
          clientTimeout: this.clientTimeout
        })), args.unshift(clear ? 1 : 0, this.instance.version), args;
      }
      convertBool(b) {
        return !!b;
      }
      __updateSettings__(options2) {
        var _this4 = this;
        return _asyncToGenerator2(function* () {
          return yield _this4.runScript("update_settings", _this4.prepareObject(options2)), parser2.overwrite(options2, options2, _this4.storeOptions);
        })();
      }
      __running__() {
        return this.runScript("running", []);
      }
      __queued__() {
        return this.runScript("queued", []);
      }
      __done__() {
        return this.runScript("done", []);
      }
      __groupCheck__() {
        var _this5 = this;
        return _asyncToGenerator2(function* () {
          return _this5.convertBool(yield _this5.runScript("group_check", []));
        })();
      }
      __incrementReservoir__(incr) {
        return this.runScript("increment_reservoir", [incr]);
      }
      __currentReservoir__() {
        return this.runScript("current_reservoir", []);
      }
      __check__(weight) {
        var _this6 = this;
        return _asyncToGenerator2(function* () {
          return _this6.convertBool(yield _this6.runScript("check", _this6.prepareArray([weight])));
        })();
      }
      __register__(index, weight, expiration) {
        var _this7 = this;
        return _asyncToGenerator2(function* () {
          var reservoir, success, wait, _ref4 = yield _this7.runScript("register", _this7.prepareArray([index, weight, expiration])), _ref5 = _slicedToArray2(_ref4, 3);
          return success = _ref5[0], wait = _ref5[1], reservoir = _ref5[2], {
            success: _this7.convertBool(success),
            wait,
            reservoir
          };
        })();
      }
      __submit__(queueLength, weight) {
        var _this8 = this;
        return _asyncToGenerator2(function* () {
          var blocked, e, maxConcurrent, overweight, reachedHWM, strategy;
          try {
            var _ref6 = yield _this8.runScript("submit", _this8.prepareArray([queueLength, weight])), _ref7 = _slicedToArray2(_ref6, 3);
            return reachedHWM = _ref7[0], blocked = _ref7[1], strategy = _ref7[2], {
              reachedHWM: _this8.convertBool(reachedHWM),
              blocked: _this8.convertBool(blocked),
              strategy
            };
          } catch (error) {
            if (e = error, e.message.indexOf("OVERWEIGHT") === 0) {
              var _e$message$split = e.message.split(":"), _e$message$split2 = _slicedToArray2(_e$message$split, 3);
              throw overweight = _e$message$split2[0], weight = _e$message$split2[1], maxConcurrent = _e$message$split2[2], new BottleneckError(`Impossible to add a job having a weight of ${weight} to a limiter having a maxConcurrent setting of ${maxConcurrent}`);
            } else
              throw e;
          }
        })();
      }
      __free__(index, weight) {
        var _this9 = this;
        return _asyncToGenerator2(function* () {
          var running;
          return running = yield _this9.runScript("free", _this9.prepareArray([index])), {
            running
          };
        })();
      }
    };
    module2.exports = RedisDatastore;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/States.js
var require_States = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/States.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var BottleneckError, States;
    BottleneckError = require_BottleneckError();
    States = class {
      constructor(status1) {
        this.status = status1, this._jobs = {}, this.counts = this.status.map(function() {
          return 0;
        });
      }
      next(id) {
        var current, next;
        if (current = this._jobs[id], next = current + 1, current != null && next < this.status.length)
          return this.counts[current]--, this.counts[next]++, this._jobs[id]++;
        if (current != null)
          return this.counts[current]--, delete this._jobs[id];
      }
      start(id) {
        var initial;
        return initial = 0, this._jobs[id] = initial, this.counts[initial]++;
      }
      remove(id) {
        var current;
        return current = this._jobs[id], current != null && (this.counts[current]--, delete this._jobs[id]), current != null;
      }
      jobStatus(id) {
        var ref;
        return (ref = this.status[this._jobs[id]]) != null ? ref : null;
      }
      statusJobs(status) {
        var k, pos, ref, results, v;
        if (status != null) {
          if (pos = this.status.indexOf(status), pos < 0)
            throw new BottleneckError(`status must be one of ${this.status.join(", ")}`);
          ref = this._jobs, results = [];
          for (k in ref)
            v = ref[k], v === pos && results.push(k);
          return results;
        } else
          return Object.keys(this._jobs);
      }
      statusCounts() {
        return this.counts.reduce((acc, v, i) => (acc[this.status[i]] = v, acc), {});
      }
    };
    module2.exports = States;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Sync.js
var require_Sync = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Sync.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var DLList, Sync;
    DLList = require_DLList();
    Sync = class {
      constructor(name, Promise2) {
        this.schedule = this.schedule.bind(this), this.name = name, this.Promise = Promise2, this._running = 0, this._queue = new DLList();
      }
      isEmpty() {
        return this._queue.length === 0;
      }
      _tryToRun() {
        var _this = this;
        return _asyncToGenerator2(function* () {
          var args, cb, error, reject, resolve, returned, task;
          if (_this._running < 1 && _this._queue.length > 0) {
            _this._running++;
            var _this$_queue$shift = _this._queue.shift();
            return task = _this$_queue$shift.task, args = _this$_queue$shift.args, resolve = _this$_queue$shift.resolve, reject = _this$_queue$shift.reject, cb = yield _asyncToGenerator2(function* () {
              try {
                return returned = yield task(...args), function() {
                  return resolve(returned);
                };
              } catch (error1) {
                return error = error1, function() {
                  return reject(error);
                };
              }
            })(), _this._running--, _this._tryToRun(), cb();
          }
        })();
      }
      schedule(task, ...args) {
        var promise, reject, resolve;
        return resolve = reject = null, promise = new this.Promise(function(_resolve, _reject) {
          return resolve = _resolve, reject = _reject;
        }), this._queue.push({
          task,
          args,
          resolve,
          reject
        }), this._tryToRun(), promise;
      }
    };
    module2.exports = Sync;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/version.json
var require_version = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/version.json"(exports2, module2) {
    module2.exports = { version: "2.19.5" };
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Group.js
var require_Group = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Group.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function _slicedToArray2(arr, i) {
      return _arrayWithHoles2(arr) || _iterableToArrayLimit2(arr, i) || _nonIterableRest2();
    }
    function _nonIterableRest2() {
      throw new TypeError("Invalid attempt to destructure non-iterable instance");
    }
    function _iterableToArrayLimit2(arr, i) {
      var _arr = [], _n = !0, _d = !1, _e = void 0;
      try {
        for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done) && (_arr.push(_s.value), !(i && _arr.length === i)); _n = !0)
          ;
      } catch (err2) {
        _d = !0, _e = err2;
      } finally {
        try {
          !_n && _i.return != null && _i.return();
        } finally {
          if (_d)
            throw _e;
        }
      }
      return _arr;
    }
    function _arrayWithHoles2(arr) {
      if (Array.isArray(arr))
        return arr;
    }
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var Events2, Group, IORedisConnection2, RedisConnection2, Scripts2, parser2;
    parser2 = require_parser();
    Events2 = require_Events();
    RedisConnection2 = require_RedisConnection();
    IORedisConnection2 = require_IORedisConnection();
    Scripts2 = require_Scripts();
    Group = function() {
      class Group2 {
        constructor(limiterOptions = {}) {
          this.deleteKey = this.deleteKey.bind(this), this.limiterOptions = limiterOptions, parser2.load(this.limiterOptions, this.defaults, this), this.Events = new Events2(this), this.instances = {}, this.Bottleneck = require_Bottleneck(), this._startAutoCleanup(), this.sharedConnection = this.connection != null, this.connection == null && (this.limiterOptions.datastore === "redis" ? this.connection = new RedisConnection2(Object.assign({}, this.limiterOptions, {
            Events: this.Events
          })) : this.limiterOptions.datastore === "ioredis" && (this.connection = new IORedisConnection2(Object.assign({}, this.limiterOptions, {
            Events: this.Events
          }))));
        }
        key(key = "") {
          var ref;
          return (ref = this.instances[key]) != null ? ref : (() => {
            var limiter2;
            return limiter2 = this.instances[key] = new this.Bottleneck(Object.assign(this.limiterOptions, {
              id: `${this.id}-${key}`,
              timeout: this.timeout,
              connection: this.connection
            })), this.Events.trigger("created", limiter2, key), limiter2;
          })();
        }
        deleteKey(key = "") {
          var _this = this;
          return _asyncToGenerator2(function* () {
            var deleted, instance;
            return instance = _this.instances[key], _this.connection && (deleted = yield _this.connection.__runCommand__(["del", ...Scripts2.allKeys(`${_this.id}-${key}`)])), instance != null && (delete _this.instances[key], yield instance.disconnect()), instance != null || deleted > 0;
          })();
        }
        limiters() {
          var k, ref, results, v;
          ref = this.instances, results = [];
          for (k in ref)
            v = ref[k], results.push({
              key: k,
              limiter: v
            });
          return results;
        }
        keys() {
          return Object.keys(this.instances);
        }
        clusterKeys() {
          var _this2 = this;
          return _asyncToGenerator2(function* () {
            var cursor, end, found, i, k, keys, len, next, start;
            if (_this2.connection == null)
              return _this2.Promise.resolve(_this2.keys());
            for (keys = [], cursor = null, start = `b_${_this2.id}-`.length, end = 9; cursor !== 0; ) {
              var _ref = yield _this2.connection.__runCommand__(["scan", cursor ?? 0, "match", `b_${_this2.id}-*_settings`, "count", 1e4]), _ref2 = _slicedToArray2(_ref, 2);
              for (next = _ref2[0], found = _ref2[1], cursor = ~~next, i = 0, len = found.length; i < len; i++)
                k = found[i], keys.push(k.slice(start, -end));
            }
            return keys;
          })();
        }
        _startAutoCleanup() {
          var _this3 = this, base;
          return clearInterval(this.interval), typeof (base = this.interval = setInterval(
            /* @__PURE__ */ _asyncToGenerator2(function* () {
              var e, k, ref, results, time, v;
              time = Date.now(), ref = _this3.instances, results = [];
              for (k in ref) {
                v = ref[k];
                try {
                  (yield v._store.__groupCheck__(time)) ? results.push(_this3.deleteKey(k)) : results.push(void 0);
                } catch (error) {
                  e = error, results.push(v.Events.trigger("error", e));
                }
              }
              return results;
            }),
            this.timeout / 2
          )).unref == "function" ? base.unref() : void 0;
        }
        updateSettings(options2 = {}) {
          if (parser2.overwrite(options2, this.defaults, this), parser2.overwrite(options2, options2, this.limiterOptions), options2.timeout != null)
            return this._startAutoCleanup();
        }
        disconnect(flush = !0) {
          var ref;
          if (!this.sharedConnection)
            return (ref = this.connection) != null ? ref.disconnect(flush) : void 0;
        }
      }
      return Group2.prototype.defaults = {
        timeout: 1e3 * 60 * 5,
        connection: null,
        Promise,
        id: "group-key"
      }, Group2;
    }.call(void 0);
    module2.exports = Group;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Batcher.js
var require_Batcher = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Batcher.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    var Batcher, Events2, parser2;
    parser2 = require_parser();
    Events2 = require_Events();
    Batcher = function() {
      class Batcher2 {
        constructor(options2 = {}) {
          this.options = options2, parser2.load(this.options, this.defaults, this), this.Events = new Events2(this), this._arr = [], this._resetPromise(), this._lastFlush = Date.now();
        }
        _resetPromise() {
          return this._promise = new this.Promise((res, rej) => this._resolve = res);
        }
        _flush() {
          return clearTimeout(this._timeout), this._lastFlush = Date.now(), this._resolve(), this.Events.trigger("batch", this._arr), this._arr = [], this._resetPromise();
        }
        add(data) {
          var ret;
          return this._arr.push(data), ret = this._promise, this._arr.length === this.maxSize ? this._flush() : this.maxTime != null && this._arr.length === 1 && (this._timeout = setTimeout(() => this._flush(), this.maxTime)), ret;
        }
      }
      return Batcher2.prototype.defaults = {
        maxTime: null,
        maxSize: null,
        Promise
      }, Batcher2;
    }.call(void 0);
    module2.exports = Batcher;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Bottleneck.js
var require_Bottleneck = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/Bottleneck.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    function _slicedToArray2(arr, i) {
      return _arrayWithHoles2(arr) || _iterableToArrayLimit2(arr, i) || _nonIterableRest2();
    }
    function _iterableToArrayLimit2(arr, i) {
      var _arr = [], _n = !0, _d = !1, _e = void 0;
      try {
        for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done) && (_arr.push(_s.value), !(i && _arr.length === i)); _n = !0)
          ;
      } catch (err2) {
        _d = !0, _e = err2;
      } finally {
        try {
          !_n && _i.return != null && _i.return();
        } finally {
          if (_d)
            throw _e;
        }
      }
      return _arr;
    }
    function _toArray(arr) {
      return _arrayWithHoles2(arr) || _iterableToArray(arr) || _nonIterableRest2();
    }
    function _nonIterableRest2() {
      throw new TypeError("Invalid attempt to destructure non-iterable instance");
    }
    function _iterableToArray(iter) {
      if (Symbol.iterator in Object(iter) || Object.prototype.toString.call(iter) === "[object Arguments]")
        return Array.from(iter);
    }
    function _arrayWithHoles2(arr) {
      if (Array.isArray(arr))
        return arr;
    }
    function asyncGeneratorStep2(gen, resolve, reject, _next, _throw, key, arg) {
      try {
        var info = gen[key](arg), value = info.value;
      } catch (error) {
        reject(error);
        return;
      }
      info.done ? resolve(value) : Promise.resolve(value).then(_next, _throw);
    }
    function _asyncToGenerator2(fn) {
      return function() {
        var self = this, args = arguments;
        return new Promise(function(resolve, reject) {
          var gen = fn.apply(self, args);
          function _next(value) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "next", value);
          }
          function _throw(err2) {
            asyncGeneratorStep2(gen, resolve, reject, _next, _throw, "throw", err2);
          }
          _next(void 0);
        });
      };
    }
    var Bottleneck2, DEFAULT_PRIORITY, Events2, Job, LocalDatastore, NUM_PRIORITIES, Queues, RedisDatastore, States, Sync, parser2, splice = [].splice;
    NUM_PRIORITIES = 10;
    DEFAULT_PRIORITY = 5;
    parser2 = require_parser();
    Queues = require_Queues();
    Job = require_Job();
    LocalDatastore = require_LocalDatastore();
    RedisDatastore = require_RedisDatastore();
    Events2 = require_Events();
    States = require_States();
    Sync = require_Sync();
    Bottleneck2 = function() {
      class Bottleneck3 {
        constructor(options2 = {}, ...invalid) {
          var storeInstanceOptions, storeOptions;
          this._addToQueue = this._addToQueue.bind(this), this._validateOptions(options2, invalid), parser2.load(options2, this.instanceDefaults, this), this._queues = new Queues(NUM_PRIORITIES), this._scheduled = {}, this._states = new States(["RECEIVED", "QUEUED", "RUNNING", "EXECUTING"].concat(this.trackDoneStatus ? ["DONE"] : [])), this._limiter = null, this.Events = new Events2(this), this._submitLock = new Sync("submit", this.Promise), this._registerLock = new Sync("register", this.Promise), storeOptions = parser2.load(options2, this.storeDefaults, {}), this._store = function() {
            if (this.datastore === "redis" || this.datastore === "ioredis" || this.connection != null)
              return storeInstanceOptions = parser2.load(options2, this.redisStoreDefaults, {}), new RedisDatastore(this, storeOptions, storeInstanceOptions);
            if (this.datastore === "local")
              return storeInstanceOptions = parser2.load(options2, this.localStoreDefaults, {}), new LocalDatastore(this, storeOptions, storeInstanceOptions);
            throw new Bottleneck3.prototype.BottleneckError(`Invalid datastore type: ${this.datastore}`);
          }.call(this), this._queues.on("leftzero", () => {
            var ref;
            return (ref = this._store.heartbeat) != null && typeof ref.ref == "function" ? ref.ref() : void 0;
          }), this._queues.on("zero", () => {
            var ref;
            return (ref = this._store.heartbeat) != null && typeof ref.unref == "function" ? ref.unref() : void 0;
          });
        }
        _validateOptions(options2, invalid) {
          if (!(options2 != null && typeof options2 == "object" && invalid.length === 0))
            throw new Bottleneck3.prototype.BottleneckError("Bottleneck v2 takes a single object argument. Refer to https://github.com/SGrondin/bottleneck#upgrading-to-v2 if you're upgrading from Bottleneck v1.");
        }
        ready() {
          return this._store.ready;
        }
        clients() {
          return this._store.clients;
        }
        channel() {
          return `b_${this.id}`;
        }
        channel_client() {
          return `b_${this.id}_${this._store.clientId}`;
        }
        publish(message) {
          return this._store.__publish__(message);
        }
        disconnect(flush = !0) {
          return this._store.__disconnect__(flush);
        }
        chain(_limiter) {
          return this._limiter = _limiter, this;
        }
        queued(priority) {
          return this._queues.queued(priority);
        }
        clusterQueued() {
          return this._store.__queued__();
        }
        empty() {
          return this.queued() === 0 && this._submitLock.isEmpty();
        }
        running() {
          return this._store.__running__();
        }
        done() {
          return this._store.__done__();
        }
        jobStatus(id) {
          return this._states.jobStatus(id);
        }
        jobs(status) {
          return this._states.statusJobs(status);
        }
        counts() {
          return this._states.statusCounts();
        }
        _randomIndex() {
          return Math.random().toString(36).slice(2);
        }
        check(weight = 1) {
          return this._store.__check__(weight);
        }
        _clearGlobalState(index) {
          return this._scheduled[index] != null ? (clearTimeout(this._scheduled[index].expiration), delete this._scheduled[index], !0) : !1;
        }
        _free(index, job, options2, eventInfo) {
          var _this = this;
          return _asyncToGenerator2(function* () {
            var e, running;
            try {
              var _ref = yield _this._store.__free__(index, options2.weight);
              if (running = _ref.running, _this.Events.trigger("debug", `Freed ${options2.id}`, eventInfo), running === 0 && _this.empty())
                return _this.Events.trigger("idle");
            } catch (error1) {
              return e = error1, _this.Events.trigger("error", e);
            }
          })();
        }
        _run(index, job, wait) {
          var clearGlobalState, free, run;
          return job.doRun(), clearGlobalState = this._clearGlobalState.bind(this, index), run = this._run.bind(this, index, job), free = this._free.bind(this, index, job), this._scheduled[index] = {
            timeout: setTimeout(() => job.doExecute(this._limiter, clearGlobalState, run, free), wait),
            expiration: job.options.expiration != null ? setTimeout(function() {
              return job.doExpire(clearGlobalState, run, free);
            }, wait + job.options.expiration) : void 0,
            job
          };
        }
        _drainOne(capacity) {
          return this._registerLock.schedule(() => {
            var args, index, next, options2, queue;
            if (this.queued() === 0)
              return this.Promise.resolve(null);
            queue = this._queues.getFirst();
            var _next2 = next = queue.first();
            return options2 = _next2.options, args = _next2.args, capacity != null && options2.weight > capacity ? this.Promise.resolve(null) : (this.Events.trigger("debug", `Draining ${options2.id}`, {
              args,
              options: options2
            }), index = this._randomIndex(), this._store.__register__(index, options2.weight, options2.expiration).then(({
              success,
              wait,
              reservoir
            }) => {
              var empty;
              return this.Events.trigger("debug", `Drained ${options2.id}`, {
                success,
                args,
                options: options2
              }), success ? (queue.shift(), empty = this.empty(), empty && this.Events.trigger("empty"), reservoir === 0 && this.Events.trigger("depleted", empty), this._run(index, next, wait), this.Promise.resolve(options2.weight)) : this.Promise.resolve(null);
            }));
          });
        }
        _drainAll(capacity, total = 0) {
          return this._drainOne(capacity).then((drained) => {
            var newCapacity;
            return drained != null ? (newCapacity = capacity != null ? capacity - drained : capacity, this._drainAll(newCapacity, total + drained)) : this.Promise.resolve(total);
          }).catch((e) => this.Events.trigger("error", e));
        }
        _dropAllQueued(message) {
          return this._queues.shiftAll(function(job) {
            return job.doDrop({
              message
            });
          });
        }
        stop(options2 = {}) {
          var done, waitForExecuting;
          return options2 = parser2.load(options2, this.stopDefaults), waitForExecuting = (at) => {
            var finished;
            return finished = () => {
              var counts;
              return counts = this._states.counts, counts[0] + counts[1] + counts[2] + counts[3] === at;
            }, new this.Promise((resolve, reject) => finished() ? resolve() : this.on("done", () => {
              if (finished())
                return this.removeAllListeners("done"), resolve();
            }));
          }, done = options2.dropWaitingJobs ? (this._run = function(index, next) {
            return next.doDrop({
              message: options2.dropErrorMessage
            });
          }, this._drainOne = () => this.Promise.resolve(null), this._registerLock.schedule(() => this._submitLock.schedule(() => {
            var k, ref, v;
            ref = this._scheduled;
            for (k in ref)
              v = ref[k], this.jobStatus(v.job.options.id) === "RUNNING" && (clearTimeout(v.timeout), clearTimeout(v.expiration), v.job.doDrop({
                message: options2.dropErrorMessage
              }));
            return this._dropAllQueued(options2.dropErrorMessage), waitForExecuting(0);
          }))) : this.schedule({
            priority: NUM_PRIORITIES - 1,
            weight: 0
          }, () => waitForExecuting(1)), this._receive = function(job) {
            return job._reject(new Bottleneck3.prototype.BottleneckError(options2.enqueueErrorMessage));
          }, this.stop = () => this.Promise.reject(new Bottleneck3.prototype.BottleneckError("stop() has already been called")), done;
        }
        _addToQueue(job) {
          var _this2 = this;
          return _asyncToGenerator2(function* () {
            var args, blocked, error, options2, reachedHWM, shifted, strategy;
            args = job.args, options2 = job.options;
            try {
              var _ref2 = yield _this2._store.__submit__(_this2.queued(), options2.weight);
              reachedHWM = _ref2.reachedHWM, blocked = _ref2.blocked, strategy = _ref2.strategy;
            } catch (error1) {
              return error = error1, _this2.Events.trigger("debug", `Could not queue ${options2.id}`, {
                args,
                options: options2,
                error
              }), job.doDrop({
                error
              }), !1;
            }
            return blocked ? (job.doDrop(), !0) : reachedHWM && (shifted = strategy === Bottleneck3.prototype.strategy.LEAK ? _this2._queues.shiftLastFrom(options2.priority) : strategy === Bottleneck3.prototype.strategy.OVERFLOW_PRIORITY ? _this2._queues.shiftLastFrom(options2.priority + 1) : strategy === Bottleneck3.prototype.strategy.OVERFLOW ? job : void 0, shifted?.doDrop(), shifted == null || strategy === Bottleneck3.prototype.strategy.OVERFLOW) ? (shifted == null && job.doDrop(), reachedHWM) : (job.doQueue(reachedHWM, blocked), _this2._queues.push(job), yield _this2._drainAll(), reachedHWM);
          })();
        }
        _receive(job) {
          return this._states.jobStatus(job.options.id) != null ? (job._reject(new Bottleneck3.prototype.BottleneckError(`A job with the same id already exists (id=${job.options.id})`)), !1) : (job.doReceive(), this._submitLock.schedule(this._addToQueue, job));
        }
        submit(...args) {
          var cb, fn, job, options2, ref, ref1, task;
          if (typeof args[0] == "function") {
            var _ref3, _ref4, _splice$call, _splice$call2;
            ref = args, _ref3 = ref, _ref4 = _toArray(_ref3), fn = _ref4[0], args = _ref4.slice(1), _splice$call = splice.call(args, -1), _splice$call2 = _slicedToArray2(_splice$call, 1), cb = _splice$call2[0], options2 = parser2.load({}, this.jobDefaults);
          } else {
            var _ref5, _ref6, _splice$call3, _splice$call4;
            ref1 = args, _ref5 = ref1, _ref6 = _toArray(_ref5), options2 = _ref6[0], fn = _ref6[1], args = _ref6.slice(2), _splice$call3 = splice.call(args, -1), _splice$call4 = _slicedToArray2(_splice$call3, 1), cb = _splice$call4[0], options2 = parser2.load(options2, this.jobDefaults);
          }
          return task = (...args2) => new this.Promise(function(resolve, reject) {
            return fn(...args2, function(...args3) {
              return (args3[0] != null ? reject : resolve)(args3);
            });
          }), job = new Job(task, args, options2, this.jobDefaults, this.rejectOnDrop, this.Events, this._states, this.Promise), job.promise.then(function(args2) {
            return typeof cb == "function" ? cb(...args2) : void 0;
          }).catch(function(args2) {
            return Array.isArray(args2) ? typeof cb == "function" ? cb(...args2) : void 0 : typeof cb == "function" ? cb(args2) : void 0;
          }), this._receive(job);
        }
        schedule(...args) {
          var job, options2, task;
          if (typeof args[0] == "function") {
            var _args = args, _args2 = _toArray(_args);
            task = _args2[0], args = _args2.slice(1), options2 = {};
          } else {
            var _args3 = args, _args4 = _toArray(_args3);
            options2 = _args4[0], task = _args4[1], args = _args4.slice(2);
          }
          return job = new Job(task, args, options2, this.jobDefaults, this.rejectOnDrop, this.Events, this._states, this.Promise), this._receive(job), job.promise;
        }
        wrap(fn) {
          var schedule, wrapped;
          return schedule = this.schedule.bind(this), wrapped = function(...args) {
            return schedule(fn.bind(this), ...args);
          }, wrapped.withOptions = function(options2, ...args) {
            return schedule(options2, fn, ...args);
          }, wrapped;
        }
        updateSettings(options2 = {}) {
          var _this3 = this;
          return _asyncToGenerator2(function* () {
            return yield _this3._store.__updateSettings__(parser2.overwrite(options2, _this3.storeDefaults)), parser2.overwrite(options2, _this3.instanceDefaults, _this3), _this3;
          })();
        }
        currentReservoir() {
          return this._store.__currentReservoir__();
        }
        incrementReservoir(incr = 0) {
          return this._store.__incrementReservoir__(incr);
        }
      }
      return Bottleneck3.default = Bottleneck3, Bottleneck3.Events = Events2, Bottleneck3.version = Bottleneck3.prototype.version = require_version().version, Bottleneck3.strategy = Bottleneck3.prototype.strategy = {
        LEAK: 1,
        OVERFLOW: 2,
        OVERFLOW_PRIORITY: 4,
        BLOCK: 3
      }, Bottleneck3.BottleneckError = Bottleneck3.prototype.BottleneckError = require_BottleneckError(), Bottleneck3.Group = Bottleneck3.prototype.Group = require_Group(), Bottleneck3.RedisConnection = Bottleneck3.prototype.RedisConnection = require_RedisConnection(), Bottleneck3.IORedisConnection = Bottleneck3.prototype.IORedisConnection = require_IORedisConnection(), Bottleneck3.Batcher = Bottleneck3.prototype.Batcher = require_Batcher(), Bottleneck3.prototype.jobDefaults = {
        priority: DEFAULT_PRIORITY,
        weight: 1,
        expiration: null,
        id: "<no-id>"
      }, Bottleneck3.prototype.storeDefaults = {
        maxConcurrent: null,
        minTime: 0,
        highWater: null,
        strategy: Bottleneck3.prototype.strategy.LEAK,
        penalty: null,
        reservoir: null,
        reservoirRefreshInterval: null,
        reservoirRefreshAmount: null,
        reservoirIncreaseInterval: null,
        reservoirIncreaseAmount: null,
        reservoirIncreaseMaximum: null
      }, Bottleneck3.prototype.localStoreDefaults = {
        Promise,
        timeout: null,
        heartbeatInterval: 250
      }, Bottleneck3.prototype.redisStoreDefaults = {
        Promise,
        timeout: null,
        heartbeatInterval: 5e3,
        clientTimeout: 1e4,
        Redis: null,
        clientOptions: {},
        clusterNodes: null,
        clearDatastore: !1,
        connection: null
      }, Bottleneck3.prototype.instanceDefaults = {
        datastore: "local",
        connection: null,
        id: "<no-id>",
        rejectOnDrop: !0,
        trackDoneStatus: !1,
        Promise
      }, Bottleneck3.prototype.stopDefaults = {
        enqueueErrorMessage: "This limiter has been stopped and cannot accept new jobs.",
        dropWaitingJobs: !0,
        dropErrorMessage: "This limiter has been stopped."
      }, Bottleneck3;
    }.call(void 0);
    module2.exports = Bottleneck2;
  }
});

// ../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/index.js
var require_lib = __commonJS({
  "../../node_modules/.pnpm/bottleneck@2.19.5/node_modules/bottleneck/lib/index.js"(exports2, module2) {
    "use strict";
    init_cjs_shims();
    module2.exports = require_Bottleneck();
  }
});

// ../cli-kit/dist/public/node/session.js
init_cjs_shims();

// ../cli-kit/dist/public/node/context/fqdn.js
init_cjs_shims();
var CouldntObtainPartnersSpinFQDNError = new AbortError("Couldn't obtain the Spin FQDN for Partners when the CLI is not running from a Spin environment."), CouldntObtainIdentitySpinFQDNError = new AbortError("Couldn't obtain the Spin FQDN for Identity when the CLI is not running from a Spin environment."), CouldntObtainShopifySpinFQDNError = new AbortError("Couldn't obtain the Spin FQDN for Shopify when the CLI is not running from a Spin environment."), NotProvidedStoreFQDNError = new AbortError("Couldn't obtain the Shopify FQDN because the store FQDN was not provided.");
async function partnersFqdn() {
  let environment = serviceEnvironment(), productionFqdn = "partners.shopify.com";
  switch (environment) {
    case "local":
      return "partners.myshopify.io";
    case "spin":
      return `partners.${await spinFqdn()}`;
    default:
      return productionFqdn;
  }
}
async function appManagementFqdn() {
  let environment = serviceEnvironment(), productionFqdn = "app.shopify.com";
  switch (environment) {
    case "local":
      return "app.shopify.myshopify.io";
    case "spin":
      return `app.shopify.${await spinFqdn()}`;
    default:
      return productionFqdn;
  }
}
async function developerDashboardFqdn() {
  let environment = serviceEnvironment(), productionFqdn = "dev.shopify.com";
  switch (environment) {
    case "local":
      return "dev.shopify.myshopify.io";
    case "spin":
      return `dev.shopify.${await spinFqdn()}`;
    default:
      return productionFqdn;
  }
}
async function businessPlatformFqdn() {
  let environment = serviceEnvironment(), productionFqdn = "destinations.shopifysvc.com";
  switch (environment) {
    case "local":
      return "business-platform.myshopify.io";
    case "spin":
      return `business-platform.${await spinFqdn()}`;
    default:
      return productionFqdn;
  }
}
async function identityFqdn() {
  let environment = serviceEnvironment(), productionFqdn = "accounts.shopify.com";
  switch (environment) {
    case "local":
      return "identity.myshopify.io";
    case "spin":
      return `identity.${await spinFqdn()}`;
    default:
      return productionFqdn;
  }
}
async function normalizeStoreFqdn(store2) {
  let storeFqdn = store2.replace(/^https?:\/\//, "").replace(/\/$/, ""), addDomain = async (storeFqdn2) => isSpinEnvironment() ? `${storeFqdn2}.shopify.${await spinFqdn()}` : `${storeFqdn2}.myshopify.com`;
  return ((storeFqdn2) => storeFqdn2.includes(".myshopify.com") || storeFqdn2.includes("spin.dev"))(storeFqdn) ? storeFqdn : addDomain(storeFqdn);
}

// ../cli-kit/dist/private/node/session/store.js
init_cjs_shims();

// ../cli-kit/dist/private/node/session/schema.js
init_cjs_shims();
var DateSchema = z.preprocess((arg) => typeof arg == "string" || arg instanceof Date ? new Date(arg) : null, z.date()), IdentityTokenSchema = z.object({
  accessToken: z.string(),
  refreshToken: z.string(),
  expiresAt: DateSchema,
  scopes: z.array(z.string())
}), ApplicationTokenSchema = z.object({
  accessToken: z.string(),
  expiresAt: DateSchema,
  scopes: z.array(z.string())
}), SessionSchema = z.object({}).catchall(z.object({
  /**
   * It contains the identity token. Before usint it, we exchange it
   * to get a token that we can use with different applications. The exchanged
   * tokens for the applications are stored under applications.
   */
  identity: IdentityTokenSchema,
  /**
   * It contains exchanged tokens for the applications the CLI
   * authenticates with. Tokens are scoped under the fqdn of the applications.
   */
  applications: z.object({}).catchall(ApplicationTokenSchema)
}));

// ../cli-kit/dist/private/node/session/store.js
async function store(session) {
  let jsonSession = JSON.stringify(session);
  setSession(jsonSession);
}
async function fetch() {
  let content = getSession();
  if (!content)
    return;
  let contentJson = JSON.parse(content), parsedSession = await SessionSchema.safeParseAsync(contentJson);
  if (parsedSession.success)
    return parsedSession.data;
  await remove();
}
async function remove() {
  removeSession();
}

// ../cli-kit/dist/private/node/session/exchange.js
init_cjs_shims();

// ../cli-kit/dist/private/node/session/identity.js
init_cjs_shims();
function clientId() {
  let environment = serviceEnvironment();
  return environment === Environment.Local ? "e5380e02-312a-7408-5718-e07017e9cf52" : environment === Environment.Production ? "fbdb2649-e327-4907-8f67-908d24cfd7e3" : "e5380e02-312a-7408-5718-e07017e9cf52";
}
function applicationId(api) {
  switch (api) {
    case "admin": {
      let environment = serviceEnvironment();
      return environment === Environment.Local ? "e92482cebb9bfb9fb5a0199cc770fde3de6c8d16b798ee73e36c9d815e070e52" : environment === Environment.Production ? "7ee65a63608843c577db8b23c4d7316ea0a01bd2f7594f8a9c06ea668c1b775c" : "e92482cebb9bfb9fb5a0199cc770fde3de6c8d16b798ee73e36c9d815e070e52";
    }
    case "partners": {
      let environment = serviceEnvironment();
      return environment === Environment.Local ? "df89d73339ac3c6c5f0a98d9ca93260763e384d51d6038da129889c308973978" : environment === Environment.Production ? "271e16d403dfa18082ffb3d197bd2b5f4479c3fc32736d69296829cbb28d41a6" : "df89d73339ac3c6c5f0a98d9ca93260763e384d51d6038da129889c308973978";
    }
    case "storefront-renderer": {
      let environment = serviceEnvironment();
      return environment === Environment.Local ? "46f603de-894f-488d-9471-5b721280ff49" : environment === Environment.Production ? "ee139b3d-5861-4d45-b387-1bc3ada7811c" : "46f603de-894f-488d-9471-5b721280ff49";
    }
    case "business-platform": {
      let environment = serviceEnvironment();
      return environment === Environment.Local ? "ace6dc89-b526-456d-a942-4b8ef6acda4b" : environment === Environment.Production ? "32ff8ee5-82b8-4d93-9f8a-c6997cefb7dc" : "ace6dc89-b526-456d-a942-4b8ef6acda4b";
    }
    case "app-management":
      return serviceEnvironment() === Environment.Production ? "7ee65a63608843c577db8b23c4d7316ea0a01bd2f7594f8a9c06ea668c1b775c" : "e92482cebb9bfb9fb5a0199cc770fde3de6c8d16b798ee73e36c9d815e070e52";
    default:
      throw new BugError(`Application id for API of type: ${api}`);
  }
}

// ../cli-kit/dist/public/node/result.js
init_cjs_shims();
var ok = (value) => new Ok(value), err = (err2) => new Err(err2), Ok = class {
  constructor(value) {
    this.value = value;
  }
  /**
   * Check if a `Result` is an `Err` inferring its type. `!isErr()` should be used before accessing the `value`
   *
   * @returns `false` as the `Resul` is `OK`
   */
  isErr() {
    return !1;
  }
  /**
   * Runs the `handler` method an return the same an unaltered copy of the `Result`. It could be used to log an
   * output when the result is `Ok` without breaking the flow
   *
   * @param handler - method to be run when the result is `Ok`
   * @returns a copy of the same `Result`
   */
  doOnOk(handler) {
    return handler(this.value), ok(this.value);
  }
  /**
   * A safe mode to throw the `error` of the `Result`
   */
  valueOrBug() {
    return this.value;
  }
  /**
   * Throws an abort error if the result doesn't represent a value.
   */
  valueOrAbort() {
    return this.value;
  }
  /**
   * Maps the value to another one with a different type. It leaves the `Error` type unaltered
   *
   * @param mapper - The mapper method to apply an `OK` value
   * @returns a new result with the new mapped value
   */
  map(mapper) {
    return ok(mapper(this.value));
  }
  /**
   * Maps the error type to another one. It leaves the `Ok` type and value unaltered
   *
   * @param _mapper - This mapper method is not used for an `Ok` value
   * @returns a new result with the new mapped error type and an value
   */
  mapError(_mapper) {
    return ok(this.value);
  }
}, Err = class {
  // eslint-disable-next-line node/handle-callback-err
  constructor(error) {
    this.error = error;
  }
  /**
   * Check if a `Result` is an `Err` inferring its type. `!isErr()` should be used before accessing the `value`
   *
   * @returns `false` as the `Resul` is `OK`
   */
  isErr() {
    return !0;
  }
  /**
   * Return an unaltered copy of the `Error` without doing anything.
   *
   * @param _handler - This handler method is not used for an `Error`
   * @returns a copy of the same `Error`
   */
  doOnOk(_handler) {
    return err(this.error);
  }
  /**
   * A safe mode to throw the `error` of the `Result`
   */
  valueOrBug() {
    throw this.error;
  }
  /**
   * Throws an abort error if the result doesn't represent a value.
   */
  valueOrAbort() {
    if (this.error instanceof FatalError)
      throw this.error;
    if (this.error instanceof import_ts_error.ExtendableError || this.error instanceof Error) {
      let error = new AbortError(this.error.message);
      throw error.stack = this.error.stack, error;
    } else
      throw new AbortError(`${this.error}`);
  }
  /**
   * Maps the value type to another one. It leaves the `Error` unaltered
   *
   * @param _mapper - This mapper method is not used for an `Error` value
   * @returns a new result with the new value type and an unaltered error
   */
  map(_mapper) {
    return err(this.error);
  }
  /**
   * Maps the error to another one with a different type. It leaves the value type unaltered
   *
   * @param mapper - The mapper method to apply an `Error` value
   * @returns a new result with the new mapped error
   */
  mapError(mapper) {
    return err(mapper(this.error));
  }
};

// ../cli-kit/dist/private/node/session/exchange.js
var InvalidGrantError = class extends import_ts_error.ExtendableError {
}, InvalidRequestError = class extends import_ts_error.ExtendableError {
};
async function exchangeCodeForAccessToken(codeData) {
  let clientId2 = await clientId(), params = {
    grant_type: "authorization_code",
    code: codeData.code,
    redirect_uri: "http://127.0.0.1:3456",
    client_id: clientId2,
    code_verifier: codeData.codeVerifier
  }, value = (await tokenRequest(params)).mapError(tokenRequestErrorHandler).valueOrBug();
  return buildIdentityToken(value);
}
async function exchangeAccessForApplicationTokens(identityToken, scopes, store2) {
  let token = identityToken.accessToken, appManagementEnabled = isTruthy(process.env.USE_APP_MANAGEMENT_API), [partners, storefront, businessPlatform, admin, appManagement] = await Promise.all([
    requestAppToken("partners", token, scopes.partners),
    requestAppToken("storefront-renderer", token, scopes.storefront),
    requestAppToken("business-platform", token, scopes.businessPlatform),
    store2 ? requestAppToken("admin", token, scopes.admin, store2) : {},
    appManagementEnabled ? requestAppToken("app-management", token, scopes.appManagement) : {}
  ]);
  return {
    ...partners,
    ...storefront,
    ...businessPlatform,
    ...admin,
    ...appManagement
  };
}
async function refreshAccessToken(currentToken) {
  let clientId2 = clientId(), params = {
    grant_type: "refresh_token",
    access_token: currentToken.accessToken,
    refresh_token: currentToken.refreshToken,
    client_id: clientId2
  }, value = (await tokenRequest(params)).mapError(tokenRequestErrorHandler).valueOrBug();
  return buildIdentityToken(value);
}
async function exchangeCustomPartnerToken(token) {
  let appId = applicationId("partners");
  try {
    return (await requestAppToken("partners", token, ["https://api.shopify.com/auth/partners.app.cli.access"]))[appId];
  } catch {
    throw new AbortError("The custom token provided is invalid.", "Ensure the token is correct and not expired.");
  }
}
async function exchangeDeviceCodeForAccessToken(deviceCode) {
  let clientId2 = await clientId(), tokenResult = await tokenRequest({
    grant_type: "urn:ietf:params:oauth:grant-type:device_code",
    device_code: deviceCode,
    client_id: clientId2
  });
  if (tokenResult.isErr())
    return err(tokenResult.error);
  let identityToken = buildIdentityToken(tokenResult.value);
  return ok(identityToken);
}
async function requestAppToken(api, token, scopes = [], store2) {
  let appId = applicationId(api), params = {
    grant_type: "urn:ietf:params:oauth:grant-type:token-exchange",
    requested_token_type: "urn:ietf:params:oauth:token-type:access_token",
    subject_token_type: "urn:ietf:params:oauth:token-type:access_token",
    client_id: await clientId(),
    audience: appId,
    scope: scopes.join(" "),
    subject_token: token,
    ...api === "admin" && { destination: `https://${store2}/admin` }
  }, identifier = appId;
  api === "admin" && store2 && (identifier = `${store2}-${appId}`);
  let value = (await tokenRequest(params)).mapError(tokenRequestErrorHandler).valueOrBug(), appToken = buildApplicationToken(value);
  return { [identifier]: appToken };
}
function tokenRequestErrorHandler(error) {
  return error === "invalid_grant" ? new InvalidGrantError() : error === "invalid_request" ? new InvalidRequestError() : new AbortError(error);
}
async function tokenRequest(params) {
  let fqdn = await identityFqdn(), url2 = new URL(`https://${fqdn}/oauth/token`);
  url2.search = new URLSearchParams(Object.entries(params)).toString();
  let res = await shopifyFetch(url2.href, { method: "POST" }), payload = await res.json();
  return res.ok ? ok(payload) : err(payload.error);
}
function buildIdentityToken(result) {
  return {
    accessToken: result.access_token,
    refreshToken: result.refresh_token,
    expiresAt: new Date(Date.now() + result.expires_in * 1e3),
    scopes: result.scope.split(" ")
  };
}
function buildApplicationToken(result) {
  return {
    accessToken: result.access_token,
    expiresAt: new Date(Date.now() + result.expires_in * 1e3),
    scopes: result.scope.split(" ")
  };
}

// ../cli-kit/dist/private/node/session.js
init_cjs_shims();

// ../cli-kit/dist/private/node/session/validate.js
init_cjs_shims();

// ../cli-kit/dist/private/node/session/identity-token-validation.js
init_cjs_shims();
async function validateIdentityToken(token) {
  if (isSpin() && firstPartyDev())
    return !0;
  try {
    return withIntrospectionURL(async (introspectionURL) => {
      let options2 = {
        method: "POST",
        headers: { Authorization: `Bearer ${token}`, "Content-Type": "application/json" },
        body: JSON.stringify({ token })
      };
      outputDebug(`Sending Identity Introspection request to URL: ${introspectionURL}`);
      let response = await shopifyFetch(introspectionURL, options2);
      if (response.ok && response.headers.get("content-type")?.includes("json")) {
        let json = await response.json();
        return outputDebug(`The identity token is valid: ${json.valid}`), ok(json.valid);
      } else {
        if (response.status === 404 || response.status > 500)
          return err(new AbortError(`The introspection endpoint returned a ${response.status}: ${introspectionURL}`));
        {
          let text = await response.text();
          return outputDebug(`The Introspection request failed with:
 - status: ${response.status}
 - www-authenticate header: ${JSON.stringify(response.headers.get("www-authenticate"))}
 - body: ${JSON.stringify(text)}`), ok(!1);
        }
      }
    });
  } catch (error) {
    return outputDebug(`The identity token is invalid: ${error}`), !1;
  }
}
async function withIntrospectionURL(fn) {
  let cacheKey = `identity-introspection-url-${await identityFqdn()}`, introspectionURL = await cacheRetrieveOrRepopulate(cacheKey, getIntrospectionURL, 6048e5), result = await fn(introspectionURL);
  if (result.isErr() && (introspectionURL = await cacheRetrieveOrRepopulate(cacheKey, getIntrospectionURL, 0), result = await fn(introspectionURL)), result.isErr())
    throw result.error;
  return result.value;
}
async function getIntrospectionURL() {
  return (await (await shopifyFetch(`https://${await identityFqdn()}/.well-known/openid-configuration.json`)).json()).introspection_endpoint;
}

// ../cli-kit/dist/private/node/session/validate.js
function validateScopes(requestedScopes, identity) {
  let currentScopes = identity.scopes;
  return firstPartyDev() !== currentScopes.includes("employee") ? !1 : requestedScopes.every((scope) => currentScopes.includes(scope));
}
async function validateSession(scopes, applications, session) {
  if (!session)
    return "needs_full_auth";
  let scopesAreValid = validateScopes(scopes, session.identity), identityIsValid = await validateIdentityToken(session.identity.accessToken);
  if (!scopesAreValid)
    return "needs_full_auth";
  let tokensAreExpired = isTokenExpired(session.identity);
  if (applications.partnersApi) {
    let appId = applicationId("partners"), token = session.applications[appId];
    tokensAreExpired = tokensAreExpired || isTokenExpired(token);
  }
  if (applications.appManagementApi) {
    let appId = applicationId("app-management"), token = session.applications[appId];
    tokensAreExpired = tokensAreExpired || isTokenExpired(token);
  }
  if (applications.storefrontRendererApi) {
    let appId = applicationId("storefront-renderer"), token = session.applications[appId];
    tokensAreExpired = tokensAreExpired || isTokenExpired(token);
  }
  if (applications.adminApi) {
    let appId = applicationId("admin"), realAppId = `${applications.adminApi.storeFqdn}-${appId}`, token = session.applications[realAppId];
    tokensAreExpired = tokensAreExpired || isTokenExpired(token);
  }
  return outputDebug(`
The validation of the token for application/identity completed with the following results:
- It's expired: ${tokensAreExpired}
- It's invalid in identity: ${!identityIsValid}
  `), tokensAreExpired ? "needs_refresh" : identityIsValid ? "ok" : "needs_full_auth";
}
function isTokenExpired(token) {
  return token ? token.expiresAt < expireThreshold() : !0;
}
function expireThreshold() {
  return new Date(Date.now() + sessionConstants.expirationTimeMarginInMinutes * 60 * 1e3);
}

// ../cli-kit/dist/private/node/session/scopes.js
init_cjs_shims();
function allDefaultScopes(extraScopes = [], systemEnvironment = process.env) {
  let scopes = allAPIs.map((api) => defaultApiScopes(api, systemEnvironment)).flat();
  return scopes = ["openid", ...scopes, ...extraScopes].map(scopeTransform), Array.from(new Set(scopes));
}
function apiScopes(api, extraScopes = [], systemEnvironment = process.env) {
  let scopes = [...defaultApiScopes(api, systemEnvironment), ...extraScopes.map(scopeTransform)].map(scopeTransform);
  return Array.from(new Set(scopes));
}
function defaultApiScopes(api, systemEnvironment = process.env) {
  switch (api) {
    case "admin":
      return ["graphql", "themes", "collaborator"];
    case "storefront-renderer":
      return ["devtools"];
    case "partners":
      return ["cli"];
    case "business-platform":
      return isTruthy(systemEnvironment.USE_APP_MANAGEMENT_API) ? ["destinations", "store-management"] : ["destinations"];
    case "app-management":
      return isTruthy(systemEnvironment.USE_APP_MANAGEMENT_API) ? ["app-management"] : [];
    default:
      throw new BugError(`Unknown API: ${api}`);
  }
}
function scopeTransform(scope) {
  switch (scope) {
    case "graphql":
      return "https://api.shopify.com/auth/shop.admin.graphql";
    case "themes":
      return "https://api.shopify.com/auth/shop.admin.themes";
    case "collaborator":
      return "https://api.shopify.com/auth/partners.collaborator-relationships.readonly";
    case "cli":
      return "https://api.shopify.com/auth/partners.app.cli.access";
    case "devtools":
      return "https://api.shopify.com/auth/shop.storefront-renderer.devtools";
    case "destinations":
      return "https://api.shopify.com/auth/destinations.readonly";
    case "store-management":
      return "https://api.shopify.com/auth/organization.store-management";
    case "app-management":
      return "https://api.shopify.com/auth/organization.apps.manage";
    default:
      return scope;
  }
}

// ../cli-kit/dist/private/node/session/authorize.js
init_cjs_shims();

// ../cli-kit/dist/private/node/session/redirect-listener.js
init_cjs_shims();

// ../cli-kit/dist/private/node/session/post-auth.js
init_cjs_shims();
var HTMLFileNames = [
  "empty-url.html",
  "auth-error.html",
  "missing-code.html",
  "missing-state.html",
  "success.html"
], StylesheetFilename = "style.css", FaviconFileName = "favicon.svg", getFilePath = async (fileName) => {
  let filePath = await findPathUp(`assets/${fileName}`, {
    type: "file",
    cwd: moduleDirectory(import.meta.url)
  });
  if (!filePath)
    throw RedirectPageAssetNotFoundError();
  return filePath;
}, getEmptyUrlHTML = async () => {
  let filePath = await getFilePath(HTMLFileNames[0]);
  return readFile(filePath);
}, getAuthErrorHTML = async () => {
  let filePath = await getFilePath(HTMLFileNames[1]);
  return readFile(filePath);
}, getMissingCodeHTML = async () => {
  let filePath = await getFilePath(HTMLFileNames[2]);
  return readFile(filePath);
}, getMissingStateHTML = async () => {
  let filePath = await getFilePath(HTMLFileNames[3]);
  return readFile(filePath);
}, getSuccessHTML = async () => {
  let filePath = await getFilePath(HTMLFileNames[4]);
  return readFile(filePath);
}, getStylesheet = async () => {
  let filePath = await getFilePath(StylesheetFilename);
  return readFile(filePath);
}, getFavicon = async () => {
  let filePath = await getFilePath(FaviconFileName);
  return readFile(filePath);
}, EmptyUrlString = "We received the authentication redirect but the URL is empty.", MissingCodeString = "The authentication can't continue because the redirect doesn't include the code.", MissingStateString = "The authentication can't continue because the redirect doesn't include the state.", RedirectPageAssetNotFoundError = () => new BugError("Redirect page asset not found");

// ../cli-kit/dist/private/node/session/redirect-listener.js
import url from "url";
import { createServer } from "http";
var ResponseTimeoutSeconds = 10, ServerStopDelaySeconds = 0.5, RedirectListener = class _RedirectListener {
  static createServer(callback) {
    return createServer(async (request, response) => {
      let requestUrl = request.url;
      if (requestUrl?.includes("favicon")) {
        let faviconFile = await getFavicon();
        return response.setHeader("Content-Type", "image/svg+xml"), response.write(faviconFile), response.end(), {};
      } else if (requestUrl === "/style.css") {
        let stylesheetFile = await getStylesheet();
        return response.setHeader("Content-Type", "text/css"), response.write(stylesheetFile), response.end(), {};
      }
      let respond = async (contents, error, state, code) => (response.setHeader("Content-Type", "text/html"), response.write(contents), response.end(), callback(error, state, code), {});
      if (!requestUrl) {
        let file2 = await getEmptyUrlHTML(), err2 = new BugError(EmptyUrlString);
        return respond(file2, err2, void 0, void 0);
      }
      let queryObject = url.parse(requestUrl, !0).query;
      if (queryObject.error && queryObject.error_description) {
        let file2 = await getAuthErrorHTML(), err2 = new AbortError(`${queryObject.error_description}`);
        return respond(file2, err2, void 0, void 0);
      }
      if (!queryObject.code) {
        let file2 = await getMissingCodeHTML(), err2 = new BugError(MissingCodeString);
        return respond(file2, err2, void 0, void 0);
      }
      if (!queryObject.state) {
        let file2 = await getMissingStateHTML(), err2 = new BugError(MissingStateString);
        return respond(file2, err2, void 0, void 0);
      }
      let file = await getSuccessHTML();
      return respond(file, void 0, `${queryObject.code}`, `${queryObject.state}`);
    });
  }
  constructor(options2) {
    this.port = options2.port, this.host = options2.host, this.server = _RedirectListener.createServer(options2.callback);
  }
  start() {
    this.server.listen({ port: this.port, host: this.host }, () => {
    });
  }
  async stop() {
    await this.server.close();
  }
};
async function listenRedirect(host, port, url2) {
  return await new Promise((resolve, reject) => {
    let timeout = setTimeout(() => {
      outputInfo(outputContent`${`
Auto-open timed out. Open the login page: `}${outputToken.link("Log in to Shopify Partners", url2)}\n`);
    }, ResponseTimeoutSeconds * 1e3), callback = (error, code, state) => {
      clearTimeout(timeout), setTimeout(() => {
        redirectListener.stop(), error ? reject(error) : resolve({ code, state });
      }, ServerStopDelaySeconds * 1e3);
    }, redirectListener = new RedirectListener({ host, port, callback });
    redirectListener.start();
  });
}

// ../../node_modules/.pnpm/get-port-please@3.0.1/node_modules/get-port-please/dist/index.mjs
init_cjs_shims();
import { createServer as createServer2 } from "node:net";
import { networkInterfaces } from "node:os";
var unsafePorts = /* @__PURE__ */ new Set([
  1,
  7,
  9,
  11,
  13,
  15,
  17,
  19,
  20,
  21,
  22,
  23,
  25,
  37,
  42,
  43,
  53,
  69,
  77,
  79,
  87,
  95,
  101,
  102,
  103,
  104,
  109,
  110,
  111,
  113,
  115,
  117,
  119,
  123,
  135,
  137,
  139,
  143,
  161,
  179,
  389,
  427,
  465,
  512,
  513,
  514,
  515,
  526,
  530,
  531,
  532,
  540,
  548,
  554,
  556,
  563,
  587,
  601,
  636,
  989,
  990,
  993,
  995,
  1719,
  1720,
  1723,
  2049,
  3659,
  4045,
  5060,
  5061,
  6e3,
  6566,
  6665,
  6666,
  6667,
  6668,
  6669,
  6697,
  10080
]);
function isUnsafePort(port) {
  return unsafePorts.has(port);
}
function isSafePort(port) {
  return !isUnsafePort(port);
}
function log(...arguments_) {
  console.log("[get-port]", ...arguments_);
}
async function getRandomPort(host) {
  let port = await checkPort(0, host);
  if (port === !1)
    throw new Error("Unable to obtain an available random port number!");
  return port;
}
async function checkPort(port, host = process.env.HOST, _verbose) {
  if (host || (host = getLocalHosts([void 0, "0.0.0.0"])), !Array.isArray(host))
    return _checkPort(port, host);
  for (let _host of host) {
    let _port = await _checkPort(port, _host);
    if (_port === !1)
      return port < 1024 && _verbose && log("Unable to listen to priviliged port:", `${_host}:${port}`), !1;
    port === 0 && _port !== 0 && (port = _port);
  }
  return port;
}
function _checkPort(port, host) {
  return new Promise((resolve) => {
    let server = createServer2();
    server.unref(), server.on("error", (error) => {
      error.code === "EINVAL" || error.code === "EADDRNOTAVAIL" ? resolve(port !== 0 && isSafePort(port) && port) : resolve(!1);
    }), server.listen({ port, host }, () => {
      let { port: port2 } = server.address();
      server.close(() => {
        resolve(isSafePort(port2) && port2);
      });
    });
  });
}
function getLocalHosts(additional) {
  let hosts = new Set(additional);
  for (let _interface of Object.values(networkInterfaces()))
    for (let config of _interface || [])
      hosts.add(config.address);
  return [...hosts];
}

// ../cli-kit/dist/private/node/session/authorize.js
var import_find_process = __toESM(require_find_process2(), 1);
async function authorize(scopes, state = randomHex(30)) {
  let host = "127.0.0.1", redirectUri = `http://${host}:3456`, fqdn = await identityFqdn(), identityClientId = clientId();
  await validateRedirectionPortAvailability(3456);
  let url2 = `http://${fqdn}/oauth/authorize`, { codeVerifier, codeChallenge } = generateRandomChallengePair(), params = {
    client_id: identityClientId,
    scope: scopes.join(" "),
    redirect_uri: redirectUri,
    state,
    response_type: "code",
    code_challenge_method: "S256",
    code_challenge: codeChallenge
  };
  return outputInfo(`
To run this command, log in to Shopify.`), outputInfo("\u{1F449} Press any key to open the login page on your browser"), await keypress(), url2 = `${url2}?${new URLSearchParams(params).toString()}`, await openURL(url2), runWithTimer("cmd_all_timing_prompts_ms")(async () => {
    let result = await listenRedirect(host, 3456, url2);
    if (result.state !== state)
      throw new AbortError("The state received from the authentication doesn't match the one that initiated the authentication process.");
    return { code: result.code, codeVerifier };
  });
}
function generateRandomChallengePair() {
  let codeVerifier = base64URLEncode(randomBytes(32)), codeChallenge = base64URLEncode(sha256(codeVerifier));
  return { codeVerifier, codeChallenge };
}
async function validateRedirectionPortAvailability(port) {
  let { killPortProcess } = await import("./lib-H3ZZGS7I.js");
  if (!await checkPort(port))
    if (await terminateBlockingPortProcessPrompt(port, "Authentication"))
      await killPortProcess(port);
    else
      throw new CancelExecution();
}
async function terminateBlockingPortProcessPrompt(port, stepDescription) {
  let processInfo = await (0, import_find_process.default)("port", port), formattedProcessName = processInfo && processInfo.length > 0 && processInfo[0]?.name ? ` (${processInfo[0].name})` : "";
  return renderConfirmationPrompt({
    message: `${stepDescription} requires a port ${port} that's unavailable because it's running another process${formattedProcessName}. Terminate that process?`,
    confirmationMessage: "Yes, terminate process in order to log in now",
    cancellationMessage: "No, cancel command and try later"
  });
}

// ../cli-kit/dist/private/node/session/device-authorization.js
init_cjs_shims();
async function requestDeviceAuthorization(scopes) {
  let fqdn = await identityFqdn(), queryParams = { client_id: clientId(), scope: scopes.join(" ") }, url2 = `https://${fqdn}/oauth/device_authorization`, jsonResult = await (await shopifyFetch(url2, {
    method: "POST",
    headers: { "Content-type": "application/x-www-form-urlencoded" },
    body: convertRequestToParams(queryParams)
  })).json();
  if (outputDebug(outputContent`Received device authorization code: ${outputToken.json(jsonResult)}`), !jsonResult.device_code || !jsonResult.verification_uri_complete)
    throw new BugError("Failed to start authorization process");
  if (outputInfo(`
To run this command, log in to Shopify.`), !isTTY())
    throw new AbortError("Authorization is required to continue, but the current environment does not support interactive prompts.", "To resolve this, specify credentials in your environment, or run the command in an interactive environment such as your local terminal.");
  outputInfo(outputContent`User verification code: ${jsonResult.user_code}`);
  let linkToken = outputToken.link(jsonResult.verification_uri_complete);
  return isCloudEnvironment() ? outputInfo(outputContent`👉 Open this link to start the auth process: ${linkToken}`) : (outputInfo("\u{1F449} Press any key to open the login page on your browser"), await keypress(), await openURL(jsonResult.verification_uri_complete), outputInfo(outputContent`Opened link to start the auth process: ${linkToken}`)), {
    deviceCode: jsonResult.device_code,
    userCode: jsonResult.user_code,
    verificationUri: jsonResult.verification_uri,
    expiresIn: jsonResult.expires_in,
    verificationUriComplete: jsonResult.verification_uri_complete,
    interval: jsonResult.interval
  };
}
async function pollForDeviceAuthorization(code, interval = 5) {
  let currentIntervalInSeconds = interval;
  return new Promise((resolve, reject) => {
    let onPoll = async () => {
      let result = await exchangeDeviceCodeForAccessToken(code);
      if (!result.isErr())
        return resolve(result.value);
      let error = result.error ?? "unknown_failure";
      switch (outputDebug(outputContent`Polling for device authorization... status: ${error}`), error) {
        case "authorization_pending":
          return startPolling();
        case "slow_down":
          return currentIntervalInSeconds += 5, startPolling();
        case "access_denied":
        case "expired_token":
        case "unknown_failure":
          return reject(result);
      }
    }, startPolling = () => {
      setTimeout(onPoll, currentIntervalInSeconds * 1e3);
    };
    startPolling();
  });
}
function convertRequestToParams(queryParams) {
  return Object.entries(queryParams).map(([key, value]) => value && `${key}=${value}`).filter((hasValue) => !!hasValue).join("&");
}

// ../cli-kit/dist/public/node/api/partners.js
init_cjs_shims();

// ../cli-kit/dist/public/node/api/graphql.js
init_cjs_shims();

// ../cli-kit/dist/private/node/api/graphql.js
init_cjs_shims();
function debugLogRequestInfo(api, query, variables, headers = {}) {
  outputDebug(outputContent`Sending ${outputToken.json(api)} GraphQL request:
  ${outputToken.raw(query.toString().trim())}
${variables ? `
With variables:
${sanitizeVariables(variables)}
` : ""}
With request headers:
${sanitizedHeadersOutput(headers)}
`);
}
function sanitizeVariables(variables) {
  let result = { ...variables };
  return "apiKey" in result && (result.apiKey = "*****"), JSON.stringify(result, null, 2);
}
function errorHandler(api) {
  return (error, requestId) => {
    if (error instanceof ClientError) {
      let { status } = error.response, errorMessage = stringifyMessage(outputContent`
The ${outputToken.raw(api)} GraphQL API responded unsuccessfully with${status === 200 ? "" : ` the HTTP status ${status} and`} errors:

${outputToken.json(error.response.errors)}
      `);
      requestId && (errorMessage += `
Request ID: ${requestId}
`);
      let mappedError;
      return status < 500 ? mappedError = new GraphQLClientError(errorMessage, status, error.response.errors) : mappedError = new AbortError(errorMessage), mappedError.stack = error.stack, mappedError;
    } else
      return error;
  };
}

// ../cli-kit/dist/public/node/api/graphql.js
async function performGraphQLRequest(options2) {
  let { token, addedHeaders, queryAsString, variables, api, url: url2, responseOptions } = options2, headers = {
    ...addedHeaders,
    ...buildHeaders(token)
  };
  debugLogRequestInfo(api, queryAsString, variables, headers);
  let clientOptions = { agent: await httpsAgent(), headers }, client = new GraphQLClient(url2, clientOptions);
  return runWithTimer("cmd_all_timing_network_ms")(async () => {
    let response = await retryAwareRequest({ request: () => client.rawRequest(queryAsString, variables), url: url2 }, responseOptions?.handleErrors === !1 ? void 0 : errorHandler(api));
    return responseOptions?.onResponse && responseOptions.onResponse(response), response.data;
  });
}
async function graphqlRequest(options2) {
  return performGraphQLRequest({
    ...options2,
    queryAsString: options2.query
  });
}
async function graphqlRequestDoc(options2) {
  return performGraphQLRequest({
    ...options2,
    queryAsString: resolveRequestDocument(options2.query).query
  });
}

// ../cli-kit/dist/public/node/api/partners.js
var import_bottleneck = __toESM(require_lib(), 1), limiter = new import_bottleneck.default({
  minTime: 150,
  maxConcurrent: 10
});
async function setupRequest(token) {
  let api = "Partners", url2 = `https://${await partnersFqdn()}/api/cli/graphql`;
  return {
    token,
    api,
    url: url2,
    responseOptions: { onResponse: handleDeprecations }
  };
}
async function partnersRequest(query, token, variables) {
  let opts = await setupRequest(token);
  return limiter.schedule(() => graphqlRequest({
    ...opts,
    query,
    variables
  }));
}
async function partnersRequestDoc(query, token, variables) {
  let opts = await setupRequest(token);
  return limiter.schedule(() => graphqlRequestDoc({
    ...opts,
    query,
    variables
  }));
}
var FunctionUploadUrlGenerateMutation = gql`
  mutation functionUploadUrlGenerateMutation {
    functionUploadUrlGenerate {
      generatedUrlDetails {
        url
        moduleId
        headers
        maxBytes
        maxSize
      }
    }
  }
`;
function handleDeprecations(response) {
  if (!response.extensions)
    return;
  let deprecationDates = [];
  for (let deprecation of response.extensions.deprecations)
    deprecation.supportedUntilDate && deprecationDates.push(new Date(deprecation.supportedUntilDate));
  setNextDeprecationDate(deprecationDates);
}

// ../cli-kit/dist/private/node/session.js
async function ensureAuthenticated(applications, _env, { forceRefresh = !1, noPrompt = !1 } = {}) {
  let fqdn = await identityFqdn(), previousStoreFqdn = applications.adminApi?.storeFqdn;
  if (previousStoreFqdn) {
    let normalizedStoreName = await normalizeStoreFqdn(previousStoreFqdn);
    previousStoreFqdn === applications.adminApi?.storeFqdn && (applications.adminApi.storeFqdn = normalizedStoreName);
  }
  let currentSession = await fetch() || {}, fqdnSession = currentSession[fqdn], scopes = getFlattenScopes(applications);
  outputDebug(outputContent`Validating existing session against the scopes:
${outputToken.json(scopes)}
For applications:
${outputToken.json(applications)}
`);
  let validationResult = await validateSession(scopes, applications, fqdnSession), newSession = {};
  function throwOnNoPrompt() {
    if (!(!noPrompt || isSpin() && firstPartyDev()))
      throw new AbortError(`The currently available CLI credentials are invalid.

The CLI is currently unable to prompt for reauthentication.`, "Restart the CLI process you were running. If in an interactive terminal, you will be prompted to reauthenticate. If in a non-interactive terminal, ensure the correct credentials are available in the program environment.");
  }
  if (validationResult === "needs_full_auth")
    throwOnNoPrompt(), outputDebug(outputContent`Initiating the full authentication flow...`), newSession = await executeCompleteFlow(applications, fqdn);
  else if (validationResult === "needs_refresh" || forceRefresh) {
    outputDebug(outputContent`The current session is valid but needs refresh. Refreshing...`);
    try {
      newSession = await refreshTokens(fqdnSession.identity, applications, fqdn);
    } catch (error) {
      if (error instanceof InvalidGrantError)
        throwOnNoPrompt(), newSession = await executeCompleteFlow(applications, fqdn);
      else
        throw error instanceof InvalidRequestError ? (await remove(), new AbortError(`
Error validating auth session`, "We've cleared the current session, please try again")) : error;
    }
  }
  let completeSession = { ...currentSession, ...newSession };
  Object.keys(newSession).length > 0 && await store(completeSession);
  let tokens = await tokensFor(applications, completeSession, fqdn), envToken = getPartnersToken();
  return envToken && applications.partnersApi && (tokens.partners = (await exchangeCustomPartnerToken(envToken)).accessToken), !envToken && tokens.partners && await ensureUserHasPartnerAccount(tokens.partners), tokens;
}
async function executeCompleteFlow(applications, identityFqdn2) {
  let scopes = getFlattenScopes(applications), exchangeScopes = getExchangeScopes(applications), store2 = applications.adminApi?.storeFqdn;
  firstPartyDev() && (outputDebug(outputContent`Authenticating as Shopify Employee...`), scopes.push("employee"));
  let identityToken, identityTokenInformation = getIdentityTokenInformation();
  if (identityTokenInformation)
    identityToken = buildIdentityTokenFromEnv(scopes, identityTokenInformation);
  else if (useDeviceAuth()) {
    outputDebug(outputContent`Requesting device authorization code...`);
    let deviceAuth = await requestDeviceAuthorization(scopes);
    outputDebug(outputContent`Starting polling for the identity token...`), identityToken = await pollForDeviceAuthorization(deviceAuth.deviceCode, deviceAuth.interval);
  } else {
    outputDebug(outputContent`Authorizing through Identity's website...`);
    let code = await authorize(scopes);
    outputDebug(outputContent`Authorization code received. Exchanging it for a CLI token...`), identityToken = await exchangeCodeForAccessToken(code);
  }
  outputDebug(outputContent`CLI token received. Exchanging it for application tokens...`);
  let result = await exchangeAccessForApplicationTokens(identityToken, exchangeScopes, store2), session = {
    [identityFqdn2]: {
      identity: identityToken,
      applications: result
    }
  };
  return outputCompleted("Logged in."), session;
}
async function ensureUserHasPartnerAccount(partnersToken) {
  if (!isTruthy(process.env.USE_APP_MANAGEMENT_API) && (outputDebug(outputContent`Verifying that the user has a Partner organization`), !await hasPartnerAccount(partnersToken) && (outputInfo(`
A Shopify Partners organization is needed to proceed.`), outputInfo("\u{1F449} Press any key to create one"), await keypress(), await openURL(`https://${await partnersFqdn()}/signup`), outputInfo(outputContent`👉 Press any key when you have ${outputToken.cyan("created the organization")}`), outputWarn(outputContent`Make sure you've confirmed your Shopify and the Partner organization from the email`), await keypress(), !await hasPartnerAccount(partnersToken))))
    throw new AbortError("Couldn't find your Shopify Partners organization", "Have you confirmed your accounts from the emails you received?");
}
var getFirstOrganization = gql`
  {
    organizations(first: 1) {
      nodes {
        id
      }
    }
  }
`;
async function hasPartnerAccount(partnersToken) {
  try {
    return await partnersRequest(getFirstOrganization, partnersToken), !0;
  } catch (error) {
    return !(error instanceof RequestClientError && error.statusCode === 404);
  }
}
async function refreshTokens(token, applications, fqdn) {
  let identityToken = await refreshAccessToken(token), exchangeScopes = getExchangeScopes(applications), applicationTokens = await exchangeAccessForApplicationTokens(identityToken, exchangeScopes, applications.adminApi?.storeFqdn);
  return {
    [fqdn]: {
      identity: identityToken,
      applications: applicationTokens
    }
  };
}
async function tokensFor(applications, session, fqdn) {
  let fqdnSession = session[fqdn];
  if (!fqdnSession)
    throw new BugError("No session found after ensuring authenticated");
  let tokens = {};
  if (applications.adminApi) {
    let appId = applicationId("admin"), realAppId = `${applications.adminApi.storeFqdn}-${appId}`, token = fqdnSession.applications[realAppId]?.accessToken;
    token && (tokens.admin = { token, storeFqdn: applications.adminApi.storeFqdn });
  }
  if (applications.partnersApi) {
    let appId = applicationId("partners");
    tokens.partners = fqdnSession.applications[appId]?.accessToken;
  }
  if (applications.storefrontRendererApi) {
    let appId = applicationId("storefront-renderer");
    tokens.storefront = fqdnSession.applications[appId]?.accessToken;
  }
  if (applications.businessPlatformApi) {
    let appId = applicationId("business-platform");
    tokens.businessPlatform = fqdnSession.applications[appId]?.accessToken;
  }
  if (applications.appManagementApi) {
    let appId = applicationId("app-management");
    tokens.appManagement = fqdnSession.applications[appId]?.accessToken;
  }
  return tokens;
}
function getFlattenScopes(apps) {
  let admin = apps.adminApi?.scopes || [], partner = apps.partnersApi?.scopes || [], storefront = apps.storefrontRendererApi?.scopes || [], businessPlatform = apps.businessPlatformApi?.scopes || [], appManagement = apps.appManagementApi?.scopes || [], requestedScopes = [...admin, ...partner, ...storefront, ...businessPlatform, ...appManagement];
  return allDefaultScopes(requestedScopes);
}
function getExchangeScopes(apps) {
  let adminScope = apps.adminApi?.scopes || [], partnerScope = apps.partnersApi?.scopes || [], storefrontScopes = apps.storefrontRendererApi?.scopes || [], businessPlatformScopes = apps.businessPlatformApi?.scopes || [], appManagementScopes = apps.appManagementApi?.scopes || [];
  return {
    admin: apiScopes("admin", adminScope),
    partners: apiScopes("partners", partnerScope),
    storefront: apiScopes("storefront-renderer", storefrontScopes),
    businessPlatform: apiScopes("business-platform", businessPlatformScopes),
    appManagement: apiScopes("app-management", appManagementScopes)
  };
}
function buildIdentityTokenFromEnv(scopes, identityTokenInformation) {
  return {
    ...identityTokenInformation,
    expiresAt: new Date(Date.now() + 30 * 24 * 60 * 60 * 1e3),
    scopes
  };
}

// ../cli-kit/dist/public/node/session.js
async function ensureAuthenticatedPartners(scopes = [], env = process.env, options2 = {}) {
  outputDebug(outputContent`Ensuring that the user is authenticated with the Partners API with the following scopes:
${outputToken.json(scopes)}
`);
  let envToken = getPartnersToken();
  if (envToken)
    return (await exchangeCustomPartnerToken(envToken)).accessToken;
  let tokens = await ensureAuthenticated({ partnersApi: { scopes } }, env, options2);
  if (!tokens.partners)
    throw new BugError("No partners token found after ensuring authenticated");
  return tokens.partners;
}
async function ensureAuthenticatedAppManagement(scopes = [], env = process.env, options2 = {}) {
  outputDebug(outputContent`Ensuring that the user is authenticated with the App Management API with the following scopes:
${outputToken.json(scopes)}
`);
  let tokens = await ensureAuthenticated({ appManagementApi: { scopes } }, env, options2);
  if (!tokens)
    throw new BugError("No App Management token found after ensuring authenticated");
  return tokens.appManagement;
}
async function ensureAuthenticatedStorefront(scopes = [], password = void 0, forceRefresh = !1) {
  if (password)
    return password;
  outputDebug(outputContent`Ensuring that the user is authenticated with the Storefront API with the following scopes:
${outputToken.json(scopes)}
`);
  let tokens = await ensureAuthenticated({ storefrontRendererApi: { scopes } }, process.env, { forceRefresh });
  if (!tokens.storefront)
    throw new BugError("No storefront token found after ensuring authenticated");
  return tokens.storefront;
}
async function ensureAuthenticatedAdmin(store2, scopes = [], forceRefresh = !1, options2 = {}) {
  outputDebug(outputContent`Ensuring that the user is authenticated with the Admin API with the following scopes for the store ${outputToken.raw(store2)}:
${outputToken.json(scopes)}
`);
  let tokens = await ensureAuthenticated({ adminApi: { scopes, storeFqdn: store2 } }, process.env, {
    forceRefresh,
    ...options2
  });
  if (!tokens.admin)
    throw new BugError("No admin token found after ensuring authenticated");
  return tokens.admin;
}
async function ensureAuthenticatedThemes(store2, password, scopes = [], forceRefresh = !1) {
  return outputDebug(outputContent`Ensuring that the user is authenticated with the Theme API with the following scopes:
${outputToken.json(scopes)}
`), password ? { token: password, storeFqdn: await normalizeStoreFqdn(store2) } : ensureAuthenticatedAdmin(store2, scopes, forceRefresh);
}
async function ensureAuthenticatedBusinessPlatform(scopes = []) {
  outputDebug(outputContent`Ensuring that the user is authenticated with the Business Platform API with the following scopes:
${outputToken.json(scopes)}
`);
  let tokens = await ensureAuthenticated({ businessPlatformApi: { scopes } }, process.env);
  if (!tokens.businessPlatform)
    throw new BugError("No business-platform token found after ensuring authenticated");
  return tokens.businessPlatform;
}
function logout() {
  return remove();
}

export {
  partnersFqdn,
  appManagementFqdn,
  developerDashboardFqdn,
  businessPlatformFqdn,
  normalizeStoreFqdn,
  ok,
  err,
  getRandomPort,
  checkPort,
  graphqlRequest,
  graphqlRequestDoc,
  require_lib,
  partnersRequest,
  partnersRequestDoc,
  FunctionUploadUrlGenerateMutation,
  handleDeprecations,
  ensureAuthenticatedPartners,
  ensureAuthenticatedAppManagement,
  ensureAuthenticatedStorefront,
  ensureAuthenticatedAdmin,
  ensureAuthenticatedThemes,
  ensureAuthenticatedBusinessPlatform,
  logout
};
//# sourceMappingURL=chunk-MQCE7QDZ.js.map
